<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>テクニカルリファレンス</title>
    <link>https://www.sbcloud.co.jp/help/</link>
    <description>Recent content on テクニカルリファレンス</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Wed, 04 Sep 2019 16:20:40 +0900</lastBuildDate>
    
	<atom:link href="https://www.sbcloud.co.jp/help/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>イントロダクション</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/container/01/introduction/</link>
      <pubDate>Wed, 04 Sep 2019 16:20:40 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/container/01/introduction/</guid>
      <description> 本記事の狙い 世間一般ではコンテナを用いた開発が一般的になりつつありますがが、Alibaba CloudでもAWSやGCP、Azureと同等かそれ以上のコンテナサービスが揃っており、使い方次第で最もコンテナのメリットを享受できるパブリッククラウドとなります。本項ではコンテナ開発の基礎から、Alibaba Cloudを最大限活用した形までを紹介いたします。
コンテナ活用とは そもそもコンテナ※を利用する事で、どんなメリットを享受できるのか。
※containerdを用いたDockerコンテナと定義
 開発スピードが早くなり、機能実装やバグ修正までの時間を短くする 開発環境と本番環境の差分が最小限となり、人的バグを極小化する オンプレミスやクラウドを問わず、デプロイが容易になる  エンドユーザがシステムを利用する上で、バックグラウンドがコンテナか仮想サーバかは関係なく、メリットを得るのはシステム開発者です。 システム開発者がAlibaba Cloudにおけるコンテナ活用で得られるメリットを、下記開発フローから順を追って紹介いたします。
開発フロー  開発環境 コンテナイメージの作成・管理 コンテナデプロイ管理 ログ管理・モニタリング  開発端末  選択肢  Windows MAC SaaS (Cloud9的な何か)  評価基準  Shell/Powershell Docker Desktop MiniKube Microk8s Alibaba Native?   バージョン管理  選択肢  Github Gitlab Bitbucket  評価基準  Alibaba Native? Documentation   イメージビルド  選択肢  Private Server (Jenkins/JenkinsX) Public Service (CircleCI/TravisCI) Alibaba Cloud Managed Service (Container Registry)   イメージリポジトリ  選択肢  Private Repository (Docker Trusted Registry) Public Repository (Dockerhub) Alibaba Cloud Managed Service (Container Registry)   管理方式  選択肢  Custom Middleware (Kubernetes/Mesos/Nomad) Managed Service (Kubernetes)   モニタリング  選択肢  Custom Middleware (Prometheus/ElasticSearch) Managed Service (CloudMonitor)    </description>
    </item>
    
    <item>
      <title>イントロダクション</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/web-application/01/introduction/</link>
      <pubDate>Wed, 04 Sep 2019 16:20:40 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/web-application/01/introduction/</guid>
      <description> 本記事の狙い パブリッククラウドの中でもAlibaba Cloudは日本での認知度が低いと言えます。 そんな中、本記事で一般的なWeb三層アプリケーションをAlibaba Cloudでどのように実現できるかを紹介する事で、読者の方々にAlibaba Cloudの基本サービスを理解を深めてもらう事を狙いとしています。言い換えれば、認知度を上げて「Alibaba Cloudが良い意味で他社クラウドサービスと変わらない事」を伝える為となります。
Web三層モデルによるアプリケーションアーキテクチャ 以下のWeb三層アプリケーションアーキテクチャの構成図に沿って解説します。
上記システム構成を以下の4つのレイヤーに分けて、それぞれAlibaba Cloudでどのような選択肢があり、どのように活用できるのかを説明いたします。
 名前解決 負荷分散 Web/APサーバ データベース  参考リンク    タイトル URL     Alibaba Cloud Solution Infrastructure Web Application Hosting.pdf http://alicloud-common.oss-ap-southeast-1.aliyuncs.com/Alibaba%20Cloud%20Solution%20Infrastructure%20-%20Web%20Application%20Hosting.pdf   How to Set up a Website (FTP Server) with Alibaba Cloud Web Hosting and Domains https://www.alibabacloud.com/getting-started/projects/how-to-set-up-a-website-with-alibaba-cloud-web    </description>
    </item>
    
    <item>
      <title>BigDataとは</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/001_what-is-bigdata/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/001_what-is-bigdata/</guid>
      <description>BigDataとは &amp;nbsp; 現在、私たちの生活の中にはあらゆる様々なものがデジタルデータとして生成・蓄積されています。
例えば水道、電気、天気、ネットワーク、工業、ショッピング、教育、病院、スポーツ、農耕、etc…
IDC調査によれば 2025年になるとデジタルデータはZbの領域に入ります。
※ 1Zb = 125EB = 125000PB = 125000000TB
このデジタルデータはどこから発生してるのか。具体例を見てみましょう。
 1回のMRIスキャンで20,000枚の画像取得。
 Googleは1日あたり35億の検索クエリを処理。
 Instagramユーザーは毎分54,000枚の写真を投稿。
 自律走行車は毎日11TBのデータを生成。
 Twitterユーザーは、毎秒3,000のTweetを投稿。
 LINEは毎日2600億のメッセージを通知。
  &amp;nbsp; これらはいつも発生し続けてるそれぞれの単なるデータ量ではなく、そのデータから重要な情報を抽出し、ビジネスでの意思決定に活用できてこそ、初めてビッグデータと呼びます。
逆に、この収集・蓄積したデータを二次、三次活用できてなければ、それはビッグデータとはいえません。例をあげますと、自律走行車の場合、車体のあちこちに様々な観点でのカメラを設置し、走行中にデータを収集しています。そこで人がいる位置、車が通る道路、交差点とのタイミング、駐車位置、などなどを動画/画像認識で抽出し、これを元にどう自律で攻略するかプロラミングを組んだり、自律走行用のMapを作成しています。Tesraが発行した1つの都市分の自律走行用のMapデータで20億ドルの価値が出たりとしています。
このように、ビッグデータはビジネス上の様々な問題に対処できることから、ビッグデータの存在はいつの間にか巨大なビジネスの場へ展開しています。

ビッグデータとビジネスの関係 &amp;nbsp; この生成し続けるデータは、ビジネス上の意思決定を裏付ける価値があります。この価値を発掘するまではただのデータとして役立たないので、ビッグデータを運用する際はデータを収集・蓄積するだけでなく、分析、解析の流れが必要になります。ビッグデータはデータ量が増えれば増えるほど、ビジネスに対してより正確かつ確実に意思決定を行うことができます。例えば、以下の例があります。
 データ・ビジネスに対する様々な精度向上が可能
 問題解決・未来予測において、より的確な解決策が見つかる
 ビジネス上、必要な断捨離ができる
 データ維持・運用システムやコスト削減の取り組みが可能
  これらについてもううちょっと説明します。

データ・ビジネスに対する様々な精度向上が可能 &amp;nbsp; 様々なデータの中には事業やビジネスを阻害する異常データ、不正データなどが混じっています。
これらを検知し、撲滅することで問題は解決します。しかしそれだけでしょうか？例えば時系列のデータで、1時間おきに100億のデータがあり、0.001%の確率で異常データ、不正データが出るとしたら、次の新しいデータが来るまでの短い時間でどうやって検知しますか？ その解決策として、機械学習を使います。機械学習とは大量のデータを反復的に学習し、そこに潜むパターンを見つけ出すことです。そして過去データを学習した結果（数式およびパターン、変化値を特定するためのスコアや変数、パラメータ値）を新たなデータにあてはめることで、パターンにしたがって異常検知や将来予測ができます。
&amp;nbsp; このように、今後新しいデータが出るとき、異常データ・不正データを検出するときは過去のデータを遡って、変化値が大きいものを検出します。そういう意味ではビッグデータは非常に重要な存在になります。
異常検知のみならず、将来の予測、データのグループ分けなど、機械学習/深層学習/強化学習をすることもできます。しかし、データ処理をするにおいてサンプルら母数が少ないと、既存データに対するアプローチ精度が保証できない課題があります。言い換えれば、データが多ければ多いほど精度が高い=確実論で事業に対する意思決定の裏付けが可能です。
問題解決・未来予測において、より的確な解決策が見つかる &amp;nbsp; ビジネス上、様々な問題に直面します。例えば売上が下がってる、20代のお客様層が少ない、購入ユーザが少ない、今後の需要予測、１億円売上を作りたい、etc&amp;hellip; これらは今あるビッグデータを使えば解決できます。
現状抱えている問題（設問）は基本的に以下２つへ分類されます。
 発生タイプ：あるべき姿は設定される（受動的）
・目標不達成問題・・・業務目標と現状のギャップが生み出す問題（ビジネス的に一番発生する問題）
・異常発生問題・・・過去の延長戦上、問題が発生。維持すべき現状から遺脱し、ギャップが生まれるケース。原因究明と対策立案/実行の緊急性が高い
設定タイプ：あるべき姿は目標を決めてる（能動的）
・設定型問題・・・現在の問題に対して、改善革命活動のように、積極的に新たな到着目標を設定することで発生する問題
・将来型問題・・・これからどこを目指していくべきかなど、将来のあるべき姿を描き、それと今を比較して、問題を定義する（例:半年後に1億円を目指す、etc）</description>
    </item>
    
    <item>
      <title>アカウント登録</title>
      <link>https://www.sbcloud.co.jp/help/getting-started/registration/</link>
      <pubDate>Mon, 22 Jul 2019 12:30:18 +0800</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/getting-started/registration/</guid>
      <description>Alibaba Cloudのアカウント登録マニュアルが以下のリンクよりダウンロードいただけます。
Alibaba Cloud登録マニュアルをダウンロード
また本アカウント登録手順は以下の流れで記載しております。
 各種登録手順のご案内
 環境設定 各種登録の流れ
  アカウントの登録手順  基本情報の入力 メールアドレスの確認 電話番号の確認 プロファイルの更新  クレジットカードの登録手順  クレジットカードの追加 有効化のための認証 本人確認チケット起票方法  アカウント登録後のお問い合わせ  チケットによるお問い合わせ   SBCloudホームページでも同様の内容が確認できます。 https://www.sbcloud.co.jp/document/account_registration</description>
    </item>
    
    <item>
      <title>アドバイザリ</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/general/advisory/</link>
      <pubDate>Mon, 22 Jul 2019 12:30:18 +0800</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/general/advisory/</guid>
      <description>Alibaba Cloud 導入アドバイザリは下記リンクから取得可能です。
Alibaba Cloud導入アドバイザリをダウンロード
本書では、Alibaba Cloud上でシステムを構築する際の「アーキテクチャの設計」、「インフラストラクチャーの構築」、「セキュリティ」、「システム運用」の4点に関わるAlibaba Cloudの構成例をご紹介します。本書を一読頂くことで、一連のプラクティスを把握頂けます。
なお、本書は公開時点でのアドバイザリであり、時間の経過とともに、プロダクトの追加や機能追加・変更等で仕様が変更になる可能性があります。内容については随時更新を行ってまりますので、最新版をご参照下さい。
 用語集 本書に扱われるサービス一覧 Alibaba Cloudアーキテクチャの全体像 ネットワークの構成
4-1. Alibaba Cloudのネットワークの考え方
4-2. ネットワーク分割
4-3. アクセス経路
4-4. アクセス制御
 セキュリテイの構成
5-1. Alibaba Cloud責任共有モデル 5-2. ID&amp;amp;アクセスマネジメント 5-3. インフラセキュリティ 5-4. ログ管理 5-5. データ保護
 運用機能
6-1 システム監視
6-2 パッチ管理
6-3 バックアップ管理
6-4 ジョブ管理
6-5 構成管理
  </description>
    </item>
    
    <item>
      <title>サービスラインナップ比較</title>
      <link>https://www.sbcloud.co.jp/help/getting-started/cloud-users/vs-aws-gcp-azure/</link>
      <pubDate>Mon, 22 Jul 2019 12:30:18 +0800</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/getting-started/cloud-users/vs-aws-gcp-azure/</guid>
      <description>2019年7月時点でのAlibaba Cloud、AWS、Azure、GCPのサービスラインアップの比較となります。
Alibaba Cloudは中国版、国際版、日本版の３つのサービスが展開されているので、それらも併せて記載しています。
AWS/Azure/GCPとの比較について ※ AlibabaCloud公式によるAWSとの比較はこちらを参照。 https://help.aliyun.com/document_detail/65455.html
※ AlibabaCloud公式によるAzureとの比較はこちらを参照。 https://help.aliyun.com/document_detail/74242.html
コンピューティング（弹性计算）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      云服务器 ECS クラウドサーバ Elastic Compute Service Elastic Compute Service EC2 Virtual Machines Compute Engine    弹性裸金属服务器（神龙） Bare Metalクラウドサーバ ECS Bare Metal Instance ECS Bare Metal Instance EC2 Bare Metal Virtual Machines Compute Engine    轻量应用服务器 軽量アプリケーションサーバー Simple Application Server        GPU 云服务器 GPUクラウドサーバ Elastic GPU Service Elastic GPU Service EC2 Elastic GPUs Virtual Machines Compute Engine    FPGA 云服务器 FPGAクラウドサーバ   AWS EC2 FPGA Virtual Machines Compute Engine    专有宿主机 専有ホスト Dedicated Host Dedicated Host       超级计算集群 スーパーコンピューティングクラスター（SCC） Super Computing Cluster Super Computing Cluster       弹性高性能计算 E-HPC 高性能コンピューティング（E-HPC） E-HPC E-HPC High Performance Computing (HPC)      批量计算 バッチ計算 Batch Compute        容器服务 コンテナサービス Container Service Container Service AWS ECS Container Service -    容器服务 Kubernetes 版 コンテナサービスKubernetes版 Container Service for Kubernetes Container Service for Kubenetes Elastic Container Service for Kubernetes Kubernetes Service Google Kubernetes Engine    弹性容器实例 ECI サーバレスコンテナサービス Elastic Container Instance  Fargate Container Instance -    容器镜像服务 コンテナミラーリングサービス Container Registry  Elastic Container Registry Container Registry Google Container Registry    弹性伸缩 Auto Scaling Auto Scaling Auto Scaling EC2 Auto Scaling Virtual Machine Scale Sets Autoscaling    资源编排 リソースの作成と管理サービス Resource Orchestration Service Resource Orchestration Service AWS CloudFormation Resource Manager Cloud Deployment Manager    函数计算 Function as a Service Function Compute Function Compute AWS Lambda Functions Cloud Functions    图形工作站 GPUワークステーション         ストレージ（存储服务）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      对象存储 OSS オブジェクトストレージ Object Storage Service Object Storage Service S3 Blob Storage Cloud Storage    块存储 ブロックストレージ Block Storage Block Storage EBS Managed Disk 永続ディスク    文件存储 NAS ファイルストレージNAS Network Attached Storage Network Attached Storage Elastic File System (EFS) File Storage Cloud Filestore    文件存储 CPFS クラウドパラレルファイルストレージ         文件存储 HDFS HDFSファイルストレージ         智能云相册 クラウドフォトアルバム         智能媒体管理 インテリジェントメディア管理         云存储网关 クラウドストレージゲートウェイ   AWS Storage Gateway StorSimple     混合云存储阵列 ハイブリッドクラウドストレージアレイ Hybrid Cloud Storage Array        CDN配信（CDN与边缘）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      CDN Content Delivery Network Alibaba Cloud CDN Alibaba Cloud CDN CloudFront CDN Cloud CDN    安全加速 SCDN Secure Content Delivery Network         全站加速 DCDN Dynamic Route for CDN Dynamic Route for CDN Dynamic route for CDN       PCDN P2P CDN         边缘节点服务 ENS Edge Node Service         データベース（数据库）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      云数据库 POLARDB MySQL、Oracle、PostgreSQLの互換性があるクラウドデータベース   Aurora  Cloud Spanner    云数据库 RDS MySQL 版 MySQL ApsaraDB RDS for MySQL ApsaraDB for RDS(MySQL) RDS for MySQL/Aurora Database for MySQL Cloud SQL for MySQL    云数据库 RDS MariaDB TX 版 MariaDB ApsaraDB for MariaDB TX  RDS for MariaDB Database for MariaDB     云数据库 RDS SQL Server 版 SQLServer ApsaraDB RDS for SQL Server ApsaraDB for RDS(SQL Server) RDS for SQL Server SQL Database Cloud SQL for SQL Server    云数据库 RDS PostgreSQL 版 PostgreSQL ApsaraDB RDS for PostgreSQL ApsaraDB for RDS(PostgreSQL) RDS for PostgreSQL/Aurora Database for PostgreSQL Cloud SQL for PostgreSQL    云数据库 RDS PPAS 版 Oracle ApsaraDB RDS for PPAS ApsaraDB for RDS(PPAS) RDS for Oracle      分布式关系型数据库服务 DRDS 分散リレーショナルデータベースサービス Distributed Relational Database Service  Aurora  Cloud Spanner    云数据库 Redis 版 Redis ApsaraDB for Redis ApsaraDB for Redis ElastiCache (Redis) Cache for Redis Cloud Memorystore    云数据库 MongoDB 版 MongoDB ApsaraDB for MongoDB ApsaraDB for MongoDB DocumentDB (with MongoDB compatibility) Cosmos DB(API for MongoDB)     TSDB 时序时空数据库 時系列データベース High-Performance Time Series Database  Timestream Time Series Insights     云数据库 HBase 版 Apache Hbase     Cloud Bigtable   iconなし 图数据库 GDB グラフデータベース   Neptune Cosmos DB(API for Gremlin)     云数据库 Memcache 版 Memcache ApsaraDB for Memcache ApsaraDB for Memcache ElastiCache (Memcached)  Cloud Memorystore    表格存储 TableStore TableStore(NoSQL) Table Store Table Store DynamoDB Cosmos DB Cloud Datastore    分析型数据库 MySQL版 MySQLをベースにした分析データベース         分析型数据库 PostgreSQL版 DWH分析データベース HybridDB for PostgreSQL AnalyticDB for PostgreSQL Redshift SQL Data Warehouse Google BigQuery    HybridDB for MySQL HybridDB for MySQL         Data Lake Analytics データレイクアナリティクス Data Lake Analytics  Athena Data Lake Analytics Google BigQuery    数据管理 DMS データ管理サービス         混合云数据库管理 HDM ハイブリッドクラウドデータベース管理サービス         クラウド通信サービス（云通信）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      短信服务 ショートメッセージサービス         语音服务 音声メッセージサービス         流量服务 移動体通信データパッケージ         物联网无线连接服务 IoT無線通信接続サービス        iconなし 号码隐私保护 モバイルプライバシー保護サービス         号码认证服务 番号認証サービス         ネットワーク（网络）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP     iconなし 云通信网络加速 クラウド通信ネットワーク高速化サービス         专有网络 VPC 専用ネットワークVPC Virtual Private Cloud Virtual Private Cloud VPC Virtual Network Cloud VPN    云解析 PrivateZone VPCのDNSサービス Alibaba Cloud PrivateZone        负载均衡 SLB 負荷分散ロードパランサ Server Load Balancer Server Load Balancer AWS Global Accelerator Traffic Manager Cloud Load Balancing    NAT 网关 NATゲートウェイ NAT Gateway NAT Gateway Internet Gateway、NAT Instance、NAT Gateway      弹性公网 IP パブリックIPリソース Elastic IP Elastic IP Elastic IP Addresses     iconなし IPv6 转换服务 IPv6変換サービス         IPv6 网关 IPv6ゲートウェイ         全局流量管理 Global Traffic Manager Global Traffic Manager Global Traffic Manager Route 53（Traffic policy) Traffic Manager Global Load Balancing   iconなし 共享带宽 帯域幅共有サービス         共享流量包 クラウド間のデータ転送 Data Transfer Plan    Cloud Storage Transfer Service    云企业网 Cloud Enterprise Network Cloud Enterprise Network Cloud Enterprise Network       VPN 网关 VPNゲートウェイ VPN Gateway VPN Gateway VPN Gateway      智能接入网关（邀测中） オンプレミスからのデータ転送 Smart Access Gateway  AWS DataSync      高速通道 専用線接続 Express Connect Express Connect AWS Direct Connect ExpressRoute Dedicated Interconnect    基本的なセキュリティ（基础安全）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      DDoS高防IP DDoS 対策 (DDoS Pro) Anti-DDoS Pro        DDoS基础防护服务 DDoS 対策 (DDoS Basic) Anti-DDoS Basic Anti-DDoS Basic AWS Shield Standard DDoS Protection     DDoS高防（国际） DDoS 対策 (Premium) Anti-DDoS Premium  AWS Shield Advanced DDoS Protection Cloud Armor    新BGP高防IP DDoS 対策 (DDoS BGP)         Web应用防火墙 Webアプリケーションファイアウォール Web Application Firewall Web Application Firewall AWS WAF Application Gateway Cloud Armor    云安全中心（态势感知） クラウドセキュリティセンター Threat Detection Service        云盾混合云 クラウド、IDC、ハイブリッドクラウドでのセキュリティ保護サービス         云安全中心（安骑士） ホストセキュリティソフトウェア Server Guard        云防火墙 クラウドファイアウォール   AWS Firewall Manager Firewall     堡垒机 セキュリティ監査管理プラットフォーム         漏洞扫描 脆弱性スキャンサービス         网站威胁扫描系统 Webサイト脅威スキャンサービス Website Threat Inspector  GuardDuty Security Center Cloud Security Command Center    アイデンティティ管理（身份管理）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      访问控制 アカウント権限管理 Resource Access Management Resource Access Management AWS Identity and Access Management Active Directory Cloud IAM    データセキュリティ（数据安全）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      SSL 证书 SSL/TLS証明書管理サービス SSL Certificates Service SSL Certificates Service AWS Certificate Manager App Service Certificates Google-managed SSL certificates    数据库审计 データベース監査サービス         加密服务 暗号化サービス        iconなし 敏感数据保护 機密データ保護サービス   AWS Secrets Manager Key Vault     密钥管理服务 キー管理 Key Management Service Key Management Service AWS Key Management Service, AWS CloudHSM, AWS Secrets Manager Key Vault Cloud Key Management Service    ビジネスセキュリティ（业务安全）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      游戏盾 ゲームシールド GameShield        内容安全 コンテンツセキュリティ Content Moderation        风险识别 リスク識別と特定サービス         实人认证 人物識別・認証サービス         爬虫风险管理 Webクローラーやbotから防御するサービス Anti-Bot Service        セキュリティサービス(安全服务)    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      安全管家 セキュリティテクノロジおよびコンサルティングサービス Managed Security service       iconなし 渗透测试 侵入テスト         安全众测 セキュリティテスト   Inspector Security Center Cloud Security Command Center   iconなし 等保咨询 セキュリティコンサルティングサービス   Inspector Security Center Cloud Security Command Center   iconなし 应急响应 セキュリティ緊急対応サービス        iconなし 漏洞扫描 脆弱性スキャンサービス        iconなし 安全培训 セキュリティトレーニング        iconなし 安全评估 セキュリティ評価サービス        iconなし 代码审计 ソースコード監査        iconなし 安全加固 セキュリティ強化サービス        iconなし 安全通告 セキュリティ監視通知サービス        iconなし PCI DSS合规咨询 PCI DSSサービス         ビッグデータ計算（大数据计算）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      MaxCompute MaxCompute MaxCompute MaxCompute Redshift SQL Data Warehouse BigQuery    E-MapReduce E-MapReduce、Hadoopクラスタの展開 E-MapReduce E-Mapreduce EMR HDInsight Cloud Datalab, Cloud Dataproc    实时计算 Realtime Compute（元はApache Flink） Realtime Compute Realtime Compute       データの可視化（数据可视化）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      DataV数据可视化 DataV、データの可視化 DataV DataV       ビッグデータの検索と分析（大数据搜索与分析）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      开放搜索 分散検索エンジンプラットフォーム   CloudSearch Search     日志服务 各種ログの一元管理 Log Service Log Service Kinesis, SQS Event Hubs, Stream Analytics Cloud Dataflow, Cloud Pub/Sub    Elasticsearch ElasticSearch Elasticsearch Elasticsearch Elasticserach Service      关系网络分析 リレーショナルネットワーク分析         画像分析 画像分析サービス         公众趋势分析 トレンド分析サービス         Quick BI BIツール Quick BI Quick BI QuickSight Power BI Data Studio    データ開発（数据开发）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      DataWorks データの可視化 DataWorks DataWorks       Dataphin データ構築と管理サービス Dataphin        阿里云DataHub ストリーム処理   Kinesis, SQS Event Hubs, Stream Analytics Cloud Dataflow, Cloud Pub/Sub    数据集成 データ統合 Data Integration Data Integration       データのレコメンデーション（数据开发）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      企业图谱 コーポレートマップ        iconなし 智能推荐 スマートレコメンデーション         インテリジェントな音声対話（智能语音交互）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      录音文件识别 録音ファイルの認識（Speech-to-Text）   Transcribe Speech Services Cloud Speech-to-Text    实时语音转写 リアルタイム音声転写         一句话识别 一文認識（Text-to-Speech）   Polly Speech Services Cloud Text-to-Speech    语音合成 音声合成         语音合成声音定制 音声データの合成およびカスタマイズ         语音模型自学习工具 音声モデル自己学習ツール         画像検索（图像搜索）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      图像搜索 画像検索 Image Search Image Search       自然言語処理（自然语言处理）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      多语言分词 テキスト上の多言語の単語・分詞の分割サービス   Comprehend Language Understanding Cloud Natural Language    词性标注 品詞タグ付けの一部         命名实体 名前付きエンティティ         情感分析 感情分析         中心词提取 中心語抽出         智能文本分类 インテリジェントテキスト分類         文本信息抽取 テキスト情報抽出         商品评价解析 製品レビューの評価分析         印刷テキスト認識（印刷文字识别）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      通用型卡证类 IDカード、銀行カード、パスポートなどカード識別サービス         汽车相关识别 免許証・ナンバープレートなど自動車関連データの識別サービス         行业票据识别 請求書・領収書の識別サービス         资产类识别 資産証明書など各証明書識別サービス         通用文字识别 画像データのテキスト認識         行业文档类识别 業界文書データのテキスト認識サービス         视频类文字识别 ビデオデータ内の字幕および文字テキスト認識サービス         自定义模板识别 ORCカスタムテンプレートを作成し認識するサービス         顔認識（人脸识别）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      人脸识别 顔認識         機械翻訳（机器翻译）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      机器翻译 機械翻訳   Translate Translator Text Cloud Translation    画像認識（图像识别）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      图像识别 画像認識   Rekognition Computer Vision Cloud Vision    コンテンツセキュリティ（内容安全）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      图片鉴黄 ポルノコンテンツ認識         图片涉政暴恐识别 写真データからテロ画像や政治的問題画像識別サービス         图片Logo商标检测 画像からロゴ検出サービス         图片垃圾广告识别 画像スパム認識         图片不良场景识别 薬物使用、ギャンブルなどの不適切なコンテンツ認識サービス         图片风险人物识别 画像から人物特定リスク識別サービス         视频风险内容识别 ビデオリスクのコンテンツ認識         文本反垃圾识别 テキストリスクのコンテンツ認識         语音垃圾识别 音声データのリスク識別サービス         機械学習プラットフォーム（机器学习平台）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      机器学习平台 PAI 機械学習プラットフォームPAI Machine Learning Platform For AI  SageMaker Machine Learning Service Cloud ML Engine   iconなし 人工智能众包 AIによるクラウドソーシング         ドメイン名とウェブサイト（域名与网站）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      域名注册 ドメイン登録サービス         域名交易 ドメイン名取引サービス         网站建设 ウェブサイト構築サポートサービス         云虚拟主机 クラウド仮想ホスト Web Hosting        海外云虚拟主机 国外Webホスティング設置サービス         云解析 DNS DNS Domains Alibaba Cloud DNS Route 53 DNS Cloud DNS    弹性Web托管 柔軟なWebホスティング   Elastic Beanstalk App Service App Engine   iconなし 备案 ドメイン登録(IPC)のためのICP代替申請サービス         知的財産サービス（知识产权服务）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      商标注册 商標登録サービス         商标交易 商標登録されてるものを購入するサービス         申請サービス（应用服务）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP     iconなし 机器人流程自动化 RPA RPA         云桌面 クラウドデスクトップ         云AP クラウドAP         API 网关 API管理 API Gateway API Gateway API Gateway API Management Cloud Endpoints/Apigee    企业邮箱 ビジネスメールボックス Alibaba Mail        邮件推送 メール送受信サービス DirectMail  Simple Email Service      インテリジェントデザインサービス（智能设计服务）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP     iconなし 鹿班 画像自動生成サービス         モバイルクラウド（移动云）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      移动推送 モバイルアプリの通知とメッセージングサービス         移动热修复 モバイルサービスのhot-fixサービス         移动测试 モバイルテストサービス   AWS Device Farm  Cloud Test Lab    移动数据分析 モバイルアプリデータ統計サービス         移动用户反馈 モバイルアプリからのフィードバックサービス        iconなし HTTPDNS モバイル開発者向けのドメイン名解決サービス         ビデオクラウド（视频云）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      音视频通信 RTC オーディオとビデオ通信RTC         视频直播 ライブビデオ ApsaraVideo Live ApsaraVideo Live AWS Elemental MediaLive Media Services - Live and On-demand Streaming     视频监控 ビデオ監視サービス         视频点播 オンデマンドオーディオ/ビデオストリーミングサービス ApsaraVideo VOD  AWS Elemental MediaPackage Media Services     媒体处理 メディア変換 ApsaraVideo for Media Processing ApsaraVideo for Media Processing Elastic Transcoder/AWS Elemental MediaConvert Media Services - Encoding (Anvato)    视频审核 ビデオ検閲サービス。ポルノや政治など禁止事項の特定をメイン         视频DNA ビデオ監査サービス。映像データから重複排除をメイン         视频智能生产 ビデオ制作サービス。映像を識別しリアルタイムでハイライトを生成         视频多模态内容理解 ビデオコンテンツ識別サービス。視覚情報、テキスト、音声および動作から家庭用品、自動車、動物、植物など1000以上のカテゴリを特定         智能封面 ビデオデータやコンテンツから最適なビデオカバー提供         智能视觉 ビデオインテリジェント。画像分類、画像検出、ビデオ分類、ビデオ認識、ライブ識別         プライベートクラウド（专有云）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      Apsara Stack オンプレミスによるAlibabaCloudサービス Apsara Stack  AWS Outposts Stack Cloud Platform Service    メッセージキューMQ（消息队列 MQ）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      消息队列 RocketMQ 分散メッセージミドルウェア   Simple Queue Service Queue Storage     消息队列 AMQP RabbitMQによるメッセージキュー         微消息队列 for IoT IoT向けマイクロメッセージキュー         消息队列 Kafka kafkaによるメッセージキュー   Managed Streaming for Kafka      消息服务 MNS 分散型メッセージキューサービス Message Service Message Service SQS (Simple Queue Service), SNS (Simple Notification Service), MQ Queue Storage, Service Bus Google Pub/Sub, GAE の Task Queue   iconなし 微服务 マイクロサービス         企业级分布式应用服务 EDAS エンタープライズ分散アプリケーションサービスEDAS Enterprise Distributed Application Service        应用配置管理 ACM アプリケーション構成管理ACM Application Configuration Management        全局事务服务 GTS グローバルトランザクションサービス         インテリジェントカスタマーサービス（智能客服）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      云呼叫中心 クラウドコールセンター         云小蜜 NLPベースの会話ロボットサービス   Lex Bot Service (Dialogflow)    智能对话分析 知的対話分析         云客服 クラウドカスタマーサービス         ブロックチェーン（区块链）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      区块链服务 ブロックチェーンサービス Blockchain as a Service Blockchain as a Service Managed Blockchain、Quantum Ledger Database Blockchain Service、Blockchain Workbench     SaaSアクセラレータ（SaaS加速器）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      宜搭 GUIベース開発サービス         モノのインターネットプラットフォーム（物联网平台）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      物联网设备接入 IoTデバイスへのアクセス         生活物联网平台 Life Internet of Thingsプラットフォーム         物联网设备管理 IoTデバイス管理         物联网数据分析 モノのインターネットデータ分析   AWS IoT Analytics Stream Analytics/Time Series Insights    iconなし 物联网一站式开发 IoT 開発Studio   AWS IoT Things Graph IoT Central     低電力WAN（低功耗广域网）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      物联网络管理平台 IoTネットワーク管理プラットフォーム         物联网无线连接服务 IoT無線通信接続サービス         エッジサービス（边缘服务）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      物联网边缘计算 IoTエッジコンピューティング   AWS Greengrass IoT Edge Cloud IoT Edge   iconなし 视频边缘智能服务 ビデオエッジインテリジェンスサービス         設備サービス（设备服务）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP     iconなし AliOS Things Alibaba Cloud用IoTオペレーティングシステム         IoTセキュリティ（物联安全）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP     iconなし 物联网设备身份认证 IoTデバイスアイデンティティ認証   AWS IoT Core IoT Hub Cloud IoT Core   iconなし 物联网安全运营中心 IoTセキュリティオペレーションセンター   AWS IoT Device Defender     iconなし 物联网可信执行环境 IoT実行環境アプリケーション   AWS IoT 1-Click     iconなし 物联网可信服务管理 IoTサービス集約管理プラットフォーム   AWS IoT Device Management IoT Hub Cloud IoT Core    ソフトとハードの統合アプリケーション（软硬一体化应用）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP     iconなし 魔笔 手書きデータの認識サービス（マジックペン）         云投屏 クラウドプロジェクションスクリーン         関連クラウド製品（相关云产品）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      智联车管理云平台 Zhilian自動車メーカー向けの自動車管理クラウドプラットフォーム         エコロジー（生态）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP     iconなし 物联网市场 IoTアプリケーション購入市場        iconなし ICA物联网标准联盟 IoTConnectivityAlliance、IoTアライアンス        iconなし 物联网测试认证服务 IoTテストおよび認証サービス         バックアップ、移行、および災害復旧（备份、迁移与容灾）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      混合云备份服务 ハイブリッドクラウドのバックアップサービス         混合云容灾服务 ハイブリットクラウドの災害復旧サービス         数据库备份 DBS データベースバックアップ Database Backup Database Backup       数据传输 DTS データ転送サービス Data Transmission Service Data Transmission Service AWS Database Migration Service, AWS Schema Conversion Tool Database Migration Service     数据库和应用迁移 ADAM データベースとアプリケーション移植サービス         闪电立方 オンラインとオフラインのデータ転送サービス（Lightning Cube）        iconなし 迁移工具 Qianyun移植ツール         開発者プラットフォーム（开发者平台）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      云效 DevOpsサービス        iconなし 开发者中心 デベロッパーセンター         物联网开发者平台 IoTプラットフォーム         APIとツール（API与工具）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP     iconなし Cloud Toolkit クラウド開発ツールキット   AWS CodeStar DevOps     OpenAPI Explorer OpenAPI Explorer        iconなし API 控制中心 APIコンソール        iconなし API 全集 APIプラットフォーム        iconなし API 错误中心 APIエラーセンター        iconなし SDK 全集 Alibaba Cloud SDKプラットフォーム   AWS Cloud9 (Visual Studio Online) (Cloud Shell Code editor)    云命令行 Cloud Shell Cloud Shell Cloud Shell AWS Systems Manager Session Manager Cloud Shell Cloud Shell    プロジェクトコラボレーション（项目协作）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP     iconなし 项目协作 クラウドエンタープライズコラボレーション         コードホスティング、倉庫（代码托管、仓库）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      代码托管 Gitライブラリホスティングサービス   AWS CodeCommit Repos Cloud Source Repositories   iconなし Maven公共仓库 Maven Public Warehouse        iconなし 制品仓库 Maven製品管理サービス         統合配送（集成交付）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP     iconなし 持续交付 継続的配信サービス         CodePipline パイプライン   AWS CodePipeline Pipelines Cloud Build    テスト（测试）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      性能测试 PTS パフォーマンステストサービス        iconなし 测试平台 クラウドサービス上のテストプラットフォーム         開発と運用（开发与运维）    icon 中国サイト コメント 国際サイト 日本サイト AWS Azure GCP      应用实时监控服务 アプリケーションリアルタイム監視サービス         云监控 クラウドモニタリング CloudMonitor CloudMonitor CloudWatch Events Event Grid、Monitor Stackdriver Monitoring   iconなし 智能顾问 AlibabaCloudコンサルティングサービス         应用高可用服务 AHAS Application High Availability Service         Node.</description>
    </item>
    
    <item>
      <title>プロダクト資料のリンク一覧</title>
      <link>https://www.sbcloud.co.jp/help/getting-started/product/links/</link>
      <pubDate>Mon, 22 Jul 2019 12:30:18 +0800</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/getting-started/product/links/</guid>
      <description> 頻繁に利用されるプロダクトの活用リンク一覧を記載します。
主要プロダクト    製品名 コンテンツテーマ URL     ECS プロダクト紹介 公式ドキュメント   ECS クイックスタート 公式ドキュメント   ECS ベストプラクティス 公式ドキュメント   RDS プロダクト紹介 公式ドキュメント   SLB プロダクト紹介 公式ドキュメント   VPC プロダクト紹介 公式ドキュメント   ExpressConnect プロダクト紹介 公式ドキュメント   CloudMonitor プロダクト紹介 公式ドキュメント   OSS プロダクト紹介 公式ドキュメント    人気のプロダクト    製品名 コンテンツテーマ URL     Container Service for Kubernetes プロダクト紹介 公式ドキュメント   MaxCompute プロダクト紹介 公式ドキュメント   Realtime Compute プロダクト紹介 公式ドキュメント   Image Search プロダクト紹介 公式ドキュメント   Anti-DDoS プロダクト紹介 公式ドキュメント    </description>
    </item>
    
    <item>
      <title>Terraformとは</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/01/how-to-use/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/01/how-to-use/</guid>
      <description>&amp;nbsp; AlibabaCloudというクラウドサービスが登場したことで、クラウドサービス上にあるECSという仮想コンピューティングを作成・破棄するのが非常に簡単になりました。ボタン一つで数分でコンピューティングを起動できます。AlibabaCloudのマネジメントコンソールはWeb上にて操作する、数多くの機能をまとめた完成度の高いGUIです。
&amp;nbsp; しかし、Web上にてGUI操作とはいえ設定項目を一つ一つずつ画面上操作するのは骨が折れるのと、小規模サービスでも構築にヒューマンエラーや運用・学習コストはどうしても付き物になります。例えばAlibabaCloud未経験者がECSをCS 100台を手動起動してみましょう。この作業にどれほどの時間がかかるか、そしてミスをゼロにして稼働できるか、という課題があります。そこで解決の道となったのがInfrastructure as Code（以降は「IaC」と略します）です。
&amp;nbsp; IaCはコード通りの内容を自動で設定する仕組みを持ちます。IaCの種類はPackerやVagrantなど様々ですが、HashiCorp社がオープンソースとして手掛けるTerraformというマルチクラウド対応プロビジョニングツールがあります。シンプルなDSL(HCL)、自由自在な変数表現と状態管理が特徴です。
&amp;nbsp; TerraformはAlibabaCloudだけでなくAmazon Web Services 、GoogleCloudPlatform、MicrosoftAzure、Docker、OpenStackなど様々なインフラに幅広く対応しています。インフラを構築するためのプロビジョニングツールであり、開発者だけなく、運用担当者でも必要となりうるプロビジョニングツールです。
&amp;nbsp; Terraformは構築したいインフラの構成をテキスト形式のテンプレートファイルに定義します（Infrastructure as Code）。「どこのリージョン」「どのスペックのECS、どのリソースを使うか」「支払い方法」「展開方法」といったインフラの状態をコードとして記述し、ターミナルからコマンドを実行するだけでクラウド上に適用 (構築) が出来ます。逆に既存のリソースをTerraformでImportすることでコード化、同じ構成のコードを他リージョンで同様展開することも可能です。 他にIaCとしてPackerやVagrantがありますが、本ガイドラインとしてはTerraformを中心とした説明で進めます。 &amp;nbsp; 構成変更や他クラウドプロパイダからのマイグレーション、同じリソースで別リージョン、別アカウントにて展開するときにIaCがあることでエラーなくシームレスに移管ができます（リソースをGUIベースでコピーすることは不可能です。） また障害や高負荷など問題発生時でも環境を復元することができるメリットもあります。
&amp;nbsp; 加えて、コードからリソースを作成することで学習コスト・運用コストを削減することができます。例えば先ほどの例、AlibabaCloud未経験者がECS 100台を手動でなくIaC、Terraformで起動すると、ミスをゼロへ抑制はもちろん、学習工数・運用保守コスト・全てが大幅に節約できます。
&amp;nbsp; また、クラウド環境（仮想環境）が登場したことで、サーバらHW、物理的リソース制約がなくなりました。これにより、サーバやネットワークを簡単に構築したり、一旦構築したものをすぐに破棄することが出来るようになったので、一度構築したインフラやリソースは変更を加えることなく破棄して、新しいものを構築する考えが可能になりました。 →このような流れは「Immutable Infrastructure（不変のインフラ）」と呼ばれ、インフラ変更履歴を管理するのではなく、動作している「インフラの状態」を管理（=必要に応じて使い捨て）からクラウド環境ではコードによるインフラ構成・構築・管理・運用を行う必要があります。
&amp;nbsp; 前置きが長くなりましたが、クラウドサービスの良いところは立案した戦略や設計をすぐに試せれるところであり、AlibabaCloudの良いところは、PaaS/IaaS/SaaS/KaaS&amp;hellip;幅多くのプロダクトサービスがあり、これらの活用によってより楽に生産的にすることができる点です。是非楽しみながらAlibabaCloudのTerraformを読み進めていただければ大変幸いです。</description>
    </item>
    
    <item>
      <title>ECSの使用可能なRegion/Spec/Price紹介</title>
      <link>https://www.sbcloud.co.jp/help/getting-started/product/ecs-by-region/</link>
      <pubDate>Mon, 22 Jul 2019 12:30:18 +0800</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/getting-started/product/ecs-by-region/</guid>
      <description>ap-northeast-1    instanceType vCPU  メモリ  イントラネット帯域幅 パケット転送速度  GPU/FPGA  ローカルストレージ  OS 従量課金 サブスクリプション サブスクリプション     ecs.c5.large 2 vCPU 4 GiB 1 Gbps 300,000 PPS - - linux ￥ 9.8 JPY /時間 ¥ 5170.00 JPY /月 ¥ 52734.00 JPY /年   ecs.c5.large 2 vCPU 4 GiB 1 Gbps 300,000 PPS - - windows ￥ 17.7 JPY /時間 ¥ 10710.00 JPY /月 ¥ 109242.</description>
    </item>
    
    <item>
      <title>CloudMonitor</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/product/cloudmonitor/cloudmonitor/</link>
      <pubDate>Sun, 19 Apr 2020 12:30:18 +0800</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/product/cloudmonitor/cloudmonitor/</guid>
      <description>本記事の狙い パブリッククラウドのメリットは、インフラ作業から開放し、サービス自体に集中できると言われていますが、基盤監視が不要ということではありません。オンプレミス環境と同様に、システム全体におけるパフォーマンス変化の把握、異常動作の検知、アラームの設定、自動バッチの実行、ログの可視化などを行う必要があります。
AlibabaCloudが提供する無料監視プロダクトCloudMonitorを利用することにより、コンソール操作、または簡単なバッチ仕込むことから、AlibabaCloud上のリソースを監視することができます。本文は、下記5つのポイントからCloudMonitorの利用方法を紹介します。
 性能監視  ECS編 RDS編 SLB編  イベント監視  ECS編 RDS編 SLB編  カスタム監視 APIにより監視データの外部連携 Grafanaにより監視データの可視化 サイト監視の実装  
1. 性能監視 AlibabaCloudの製品を利用するだけで、無料で付いてくるCloudMonitor監視です。手間かかる設定が必要ありません。CloudMonitorのコンソールにて、下記リストされた各製品のメトリック項目の時系列監視図の確認はもちろん、アラームを設定することも可能です。ECS製品の場合、エージェントをECSにインストールすることにより、監視可能なメトリックが更に豊富になります。

ECS編 ・基本監視（エージェント不要）    メトリック項目 説明 単位     ECS.CPUUtilization CPUの使用率 ％   ECS.InternetInRate インターネットインバウンドの帯域幅 ビット/秒   ECS.IntranetInRate イントラネットインバウンドの帯域幅 ビット/秒   ECS.InternetOutRate インターネットアウトバウンドの帯域幅 ビット/秒   ECS.IntranetOutRate イントラネットアウトバウンドの帯域幅 ビット/秒   ECS.SystemDiskReadbps 1秒あたりのシステムディスク読取バイト数 バイト/秒   ECS.SystemDiskWritebps 1秒あたりのシステムディスク書込バイト数 バイト/秒   ECS.</description>
    </item>
    
    <item>
      <title>ECSとSpringBootの構築例</title>
      <link>https://www.sbcloud.co.jp/help/scenario/web-application/springboot-with-ecs/</link>
      <pubDate>Mon, 23 Sep 2019 16:20:40 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/scenario/web-application/springboot-with-ecs/</guid>
      <description>目次
 ECSとSpringBootを用いたWebアプリケーション構築の流れ  VPCを用いたネットワークセグメント作成 ECSを用いた仮想マシンの作成 RDSを用いたMySQLインスタンスの作成 Cent OS上でのSpringBootの実装と接続確認 SLBを用いたロードバランサーの作成    id=&amp;ldquo;VPC&amp;rdquo;&amp;gt;
1. VPCを用いたネットワークセグメント作成 &amp;nbsp; Alibaba Cloudで、VPCとそれに付随するサブネット(VSwitchと呼ばれる)を作成したいと思います。
1-1. サービスの選択 &amp;nbsp; ログイン後のコンソールで、「Virtual Private Cloud」を選択します。 1-2. VPCの作成 &amp;nbsp; 「VPCの作成」をクリックします。 以下のVPCパラメータを入力します。
 VPC名 IPv4 CIDR ブロック   1-3. VSwitchの作成 &amp;nbsp; 続けて同じ画面で、VSwitchと呼ばれるサブネットを作成します。 パラメータとしては以下の3つを入力、アベイラビリティゾーン分ける為、計2つのVSwitchを作成します。
 VPC名 アベイラビリティゾーン IPv4 CIDR ブロック
「OK」をクリックした後、「完了」をクリックします。   1-4. VPCとVSwitchの確認 &amp;nbsp; 「完了」をクリック後、VPCが作成されている事が確認できます。 &amp;nbsp; また、VSwitchのダッシュボードより、VSWitchが作成されている事も確認できます。 
2. ECSを用いた仮想マシンの作成 &amp;nbsp; Alibaba CloudのECSにおける仮想マシン作成手順を記します。また、AWSに知見のある方向けに、AWSとの違いも一部記します。
2-1. ECSサービスの選択 ログイン後のコンソールで「Elastic Compute Service」（以下ECS）をクリックします ECSダッシュボード画面で「インスタンス」をクリックします ※AWSとの違い: ECSダッシュボード画面では全リージョンのインスタンスの利用状況が表示される 2-2.</description>
    </item>
    
    <item>
      <title>Hadoopとその周辺の技術について</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/002_hadoop-and-ecosystem-technologies/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/002_hadoop-and-ecosystem-technologies/</guid>
      <description>&amp;nbsp; Hadoopとその技術レイヤーについて BigDataはRDBMSでないとだめか？ BigDataは今後の事業貢献や継続アプローチとしても欠かせません。そこで素朴な質問です。多くの人は「BigDataはRDBMSでないとだめか？」と問いますが、答えはデータサイズに伴うI/O性能の限界に伴う問題です。
例えばの話、MySQL、PostgreSQL、SQL Server、OracleなどRDBMSでHDDに200TB分のデータがあるとして、HDDは今でも最大100MB/秒でデータを読み込むため、200TBのデータを読み込むために200×1000×1000 / 100 = 2000000秒、約23日と時間がかかります。SSDも同様です。
この問題を解決するために、Hadoopなど並列分散処理が必要になります。
&amp;gt;ただし、(後述しますが)HadoopはサーバとサーバをNW接続しながら分散処理する一方、RDBMSやNoSQLはストレージと隣接するためORM（レスポンス）に特化しており、数百人以上の同時操作などオペレーション系業務では性能要件を満たしてるため、TBまでの少ないデータ量であればまだ現役です。
&amp;nbsp; BigDataを支える技術レイヤー:Hadoop 通常、データ量が100TB、1PBと多いほどI/O処理から取得や更新にどうしても時間がかかります。それを解決するためにApache Hadoopというオープンソースプラットフォームが登場しました。Hadoopは１つのマスタサーバ/ネームノードと、複数のスレーブサーバ/データノードをhostで接続しながら、マスタサーバ/ネームノードの指示によりデータストレージとデータ処理に対しスケーラブルながら分散処理、そしてフォールトトレラントによる耐性障害を備っています。
&amp;nbsp; BigDataを支える技術レイヤー:HDFS Hadoopの分散ファイルシステムとしてHDFS（Hadoop Distributed（分散） File（ファイル） System（システム））があります。こちらはHadoopら大規模データを前提に開発されたものです。大量のデータをブロック単位で分割し多数のノードに3つのレプリカとして重複保存されます。そのため、1つのサーバが壊れても、通じて生きてるサーバが自動で複製、データは常に３つのレプリカがあるよう保ってくれるので、障害にも強いです。
&amp;nbsp; BigDataを支える技術レイヤー:MapReduce Hadoop、HDFSだけでも運用できますが、データ取得や更新時はHDFS同期処理、障害問題、ネットワーク帯域負荷問題があります。それを解決するのがMapReduceという並列分散処理です。例えば、選挙の投票用紙を集計し結果を表示する流れをMapReduceで位置づけすると、以下のような図になります。投票箱にて投稿したデータは、それぞれのスタッフが分散して（Map/Shuffle/Reduce）の3パートに区切って集計するのと同じようなイメージになります。ここで言うスタッフはスレーブサーバ/データノードの位置付けで、スレーブサーバ/データノード（スタッフ）は処理の際、ノード（Disk）へ記録するため、が万が一傷害など有事に遭遇しても、代わりのスレーブサーバ/データノード（スタッフ）が引き継いて作業を行うことができます。
&amp;nbsp; BigDataを支える技術レイヤー:YARN MapReduceがあることで並列分散処理が出来ました。しかし、MapReduceは親ノードが子ノード（データノード）にプログラムを送信して計算処理するため、データを持ってないノード含め全送信するなど、処理速度・I/O負荷の面で課題があります。それを解決するためにYARNが登場しました。YARNはYet-Another-Resource-Negotiatorの略称、汎用的なクラスタリソース管理フレームワークです。YARNはリソースをによって効率的な計算処理送信で無駄を省くため、処理速度の向上・I/O負荷が減ります。そのため、YARNはMapReduce処理、Spark Streamingのようなストリーミング処理など、様々なMapReduce処理内容に応じてHadoopクラスタ(HDFS)上で効率よく並列分散処理を実現することができます。
上記のMapReduceを選挙集計で例えたものに、YARNを追加してみます。その場合、以下のストーリーになります。
スレーブサーバ/データノード（スタッフ）はリソース（人手）が限られてるため、YARNのResourceManager（管理者）が
 実際に処理したい内容を全体で確認します。今回はAさんのみ集計したいので、Aさん以外は無視しAさんのみを集計します。
 ResourceManager（管理者）にて、処理したい内容を実現するためには、スレーブサーバ/データノード（スタッフ）でどれぐらいのリソースが必要かを事前確認します。
 それぞれのスレーブサーバ/データノード（スタッフ）にリソース割り当てを実施します。
 ResourceManager（管理者）にて、スレーブサーバ/データノード（スタッフ）の処理リソース割り当てができたら、分散・リソース処理を実施します。今回はAさんのみ集計なので、Aさんに集中、そのため全スレーブサーバ/データノード（スタッフ）のI/O負荷を総合的に減らすことができます。
  &amp;nbsp; BigDataを支える技術レイヤー:Apache Hive MapReduceによって並列分散処理が簡単になりましたが、こちらは基本的にはJavaで書かなければならないことや、処理の都度コンパイルするなど、各自MapReduce処理の実装が大変という問題がありました。それを解決するためにApache Hiveが登場しました。SQLクエリ言語を書くだけで、Hiveサーバ側がMapReduceするようコンパイルし、MapReduce処理を実行してくれます。
&amp;nbsp; BigDataを支える技術レイヤー:Apache Spark HiveでSQLを使ってMapReduce処理が簡単に実現できるようになりましたが、処理速度の課題がありました。Hive（MapReduce）は基本的に処理の都度ストレージへ書き込み処理をするため、処理速度に時間がかかります。それを解決するためにオンメモリで処理するApache Sparkが登場しました。現在、Apache Sparkはビッグデータ処理基盤に幅広くサポートしており、ストリーミング、OLAP、OLTP、機械学習、深層学習、コンテナ、CI/CD、パイプライン、ETL、FaaSなどでも活躍しています。
&amp;nbsp; その他、Hadoopと周辺エコシステム 上記、Haddop、MapReduce、YARN、HDFS、Hive、Sparkなどを軽く説明しましたが、この他にHadoop周辺エコシステムが多数あります。HDFSをRDBMSとして扱うkuduに、高速OLAPするImpala、分散ストリーミングのflink、などがあります。こちらは別のページにて順次説明します。</description>
    </item>
    
    <item>
      <title>開発環境</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/container/02/development-environment/</link>
      <pubDate>Tue, 13 Aug 2019 16:20:40 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/container/02/development-environment/</guid>
      <description>以下の区分により、コンテナを活用したAlibaba Cloudにおける開発手法を紹介いたします。
 開発環境 コンテナイメージの作成・管理 コンテナデプロイ管理 ログ管理とモニタリング  本項目では、 開発環境 に焦点を当てて、開発端末とバージョン管理システムの選択肢を紹介します。 その後、Alibaba Cloudにおける推奨を紹介します。
目次  開発端末 バージョン管理 Alibaba Cloudにおける推奨  開発端末  Windows macOS Linux/その他  Windows プライベートでもビジネスでも最もよく利用されているOSはWindowsであり、慣れ親しんだUIのまま開発できるメリットは大きいです。 開発ツールとして、Docker Desktop for Windowsが提供されており、Bash for Windowsや各種IDEのDocker Clientプラグインと併せて、よく利用されます。
ただ、Windowsのデスクトップ上でDockerコンテナを利用する為にはEditionやBIOSにおいて制限をクリアする必要があります。具体的にはOSがWindows 10 64-bitで、EditionはPro、Enterprise、もしくはEducationのいずれか、かつHyper-Vが有効化されている必要があります。最新の情報は以下の公式ホームページより確認ください。
Docker Desktop for Windowsインストール要件：https://docs.docker.com/docker-for-windows/install/
上記要件を満たしている場合には、Bash for Windowsを併せてインストールする事で、Windows上でDockerコンテナの開発環境が整います。
Docker Desktop for Windowsのインストール要件を満たしていない場合には、Vagrantやパブリッククラウド上でLinuxを稼働させる形で開発環境を整えます。
macOS macOSで開発する場合には、Windowsと比較して制限は少なく、OS X Sierra 10.12かそれより新しいOSが利用要件となります。 手順として、以下DockerhubのURLよりdmgパッケージをダウンロードします。 https://hub.docker.com/editions/community/docker-ce-desktop-mac
その後、以下のDocker公式のURLの手順を参照して、インストールする事でDockerコンテナが利用可能となります。
https://docs.docker.com/docker-for-mac/install/
Linux/その他 LinuxもmacOSと同様、以下の公式URLからインストールできます。OSによってコマンドが異なりますが、Dockerを含むパッケージリポジトリを登録して、OSのパッケージ管理コマンドを用いて、ダウンロードおよびインストールする流れとなります。
CentOS / Debian / Fedora / Ubuntu
バージョン管理リポジトリ  Github/Gitlab/Bitbucket それ以外のリポジトリ  Github/GitLab/Bitbucket コンテナを活用した開発では、Gitを用いた形が一般的です。</description>
    </item>
    
    <item>
      <title>インストール</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/02/install/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/02/install/</guid>
      <description>本章は Terraform のインストール方法を学びます。
 ※ Mac/Linuxでのインストール方法になります。Windows版でのTerraform導入方法は別途記載予定です。 ※ Terraformバージョン違いを防止するためにtfenvで管理をする方法がありますが、これとは別に Dockerを使った方法もありますので参考にしてください。
 1. Homebrew &amp;nbsp; Terraformは前章で説明した通り、HashiCorp社がオープンソースとして展開してるツールです。基本的にはバージョンアップに 追従しやすい tfenv の利用を推奨しますが、お試しであればHomebrew も手軽です。 macOS の場合は次のように、Homebrew を使ってインストールできます。
$ brew install terraform $ terraform --version Terraform v0.11.13  
2. tfenv tfenvは Terraformのバージョン管理マネージャです。 tfenvを使うことで、異なるバージョンのTerraformを差異なく利用できます。
$ brew install tfenv $ tfenv --version tfenv 0.6.0  完了したら、インストール可能なTerraform のバージョンを確認します。
$ tfenv list-remote 0.12.0-beta1 0.11.13 ・・・  最新の安定バージョンかつAlibabaCloud Terraform対応は 0.11.13です。0.11.13を次のようにインストールします。
$ tfenv install 0.11.13  terraformには .terraform-versionというファイルがあり、こちらにバージョンを記述すると、そのバージョンを自動的にインストールできます。
$ echo 0.11.13 &amp;gt; .</description>
    </item>
    
    <item>
      <title>名前解決</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/web-application/02/name-resolve/</link>
      <pubDate>Mon, 13 May 2019 16:20:40 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/web-application/02/name-resolve/</guid>
      <description>以下の区分により、Alibaba Cloudを活用したWebアプリケーション構築手法を紹介いたします。
 名前解決 負荷分散 Web/APサーバ データベース/キャッシュ  本項目では、Alibaba Cloudの名前解決に関するサービスの仕様と設計ポイントを紹介します。
名前解決  対象サービス 基本的な仕様 設計のポイント 参考リンク一覧  対象サービス 名前解決に関するサービスは2種類あり、DomainとCloud DNSになります。 Domainでは、ドメインのレジストリ登録や管理を行い、Cloud DNSではAレコードやMXレコードの登録や削除等のゾーンの管理を行います。
基本的な仕様 Domain  新規ドメインを購入する際、ICANN情報を入力します。
 .cnドメインの取得もサポートしています。
 1年〜10年単位でドメインを購入できます。
 レジスタラはALIBABA.COM SINGAPORE E-COMMERCE PRIVATE LIMITEDになります。
 DNSSECを有効化できます。
 ドメインの移管（転入転出）にも対応しています。
 ドメインの移管及び更新に対するセキュリティロックを有効化できます。
 当該ドメインに対する変更証跡をコンソールから確認できます。
 デフォルトでAlibaba Cloudのネームサーバ（e.g. ns7.alidns.comとns8.alidns.com）を利用しますが、独自のDNSサーバへ変更できます。     Cloud DNS  DNSレコード管理を行い、ロードバランサや仮想サーバの名前解決をサポートします。
 デフォルトではインターネット公開向けですが、プライベートゾーンへも変更可能です。
 オペレーションログをコンソールから確認できます。
 デフォルトは無料版であり、Cloud DNS有料版を購入する事で以下の対応ができるようになります。
 レコード登録数やサブドメインレベルの上限緩和
 QPS上限設定によるDNS攻撃からの保護
 クエリボリュームの確認</description>
    </item>
    
    <item>
      <title>Linkkit SDK 利用ガイド</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/product/linkkit-sdk/</link>
      <pubDate>Wed, 05 Feb 2020 12:30:18 +0800</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/product/linkkit-sdk/</guid>
      <description>Tags ： AlibabaCloud IOT-Platform Linkkit
目的 Link Kit SDKは、Alibaba Cloudによってデバイスメーカーに提供され、デバイスに統合し、デバイスをAlibaba Cloud IoTプラットフォームに安全に接続し、Alibaba Cloud IoTプラットフォームによってデバイスを制御および管理できるようにします。デバイスは、Link Kit SDKを統合するためにTCP / IPプロトコルスタックをサポートする必要があります。zigbeeやKNXなどの非IPデバイスの場合、ゲートウェイデバイスを介してAlibaba Cloud IoTプラットフォームに接続する必要があり、ゲートウェイデバイスはLink Kit SDKを統合する必要があります。
本書はLink Kit SDK 関連の知識や Link Kit SDKを使ってIOT Platformと繋がる方法を紹介させてください。
本ガイドの全体的な流れは下記の通りです。
   セクション Topic 説明     概要紹介 Linkkit SDK と　AliOS things Linkkit SDK と　AliOS things の関係の紹介   - SDK利用以外の方法 SDK以外でIOT Platformへ繋がる方法を説明   - アーキテクチャ アーキテクチャ 基本特徴を紹介   - SDKバージョンと区別 各バージョンの紹介   - 製品の範囲 適用デバイスの紹介   開発プロセス 開発プロセス 一般的な開発プロセスの紹介   C言語Link Kit SDK紹介 C言語Link Kit SDK紹介 C言語SDKの開発概要を紹介   開発サンプル Linuxベースの開発事例 １つ簡単な開発事例を紹介    概要紹介 Linkkit SDKの概要について紹介させてください。</description>
    </item>
    
    <item>
      <title>AliOS Things 利用ガイド</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/product/ali0s-things/</link>
      <pubDate>Sat, 01 Feb 2020 12:30:18 +0800</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/product/ali0s-things/</guid>
      <description>Tags ： AlibabaCloud AliOS-Things IOT
目的 Alibaba Cloud IoT IoTオペレーティングシステム（別名AliOS Things）は、Alibaba CloudのIoT分野向けの拡張性の高いIoTオペレーティングシステムです。 AliOS Thingsは、極端なパフォーマンス、最小限の開発、クラウド統合、豊富なコンポーネント、セキュリティ保護などの主要な機能を備えたクラウド統合IoTインフラストラクチャの構築に取り組んでいます。 AliOS Thingsは、Alibaba Cloud Linkプラットフォームに接続されたさまざまなデバイスをサポートしており、スマートホーム、スマートシティ、産業、新しい旅行などの分野で広く使用できます。
本書はAliOS Things 関連の知識や AliOS Thingsを使ってIOT Platformと繋がる方法を紹介させてください。
本ガイドの全体的な流れは下記の通りです。
   セクション Topic 説明     前提知識 AliOS と AliOS things AliOS と AliOS things の関係の紹介   - AliOS things　と IOT Platform AliOS things　と IOT Platform の関係   基本構成 基本特徴 AliOS things 基本特徴を紹介   - アーキテクチャ AliOS things アーキテクチャを紹介   - 関連ハードウェア 関連ハードウェアと開発Board紹介   - 開発ツール 開発ツールAliOS Things Studio   開発サンプル AliOSの開発事例 AliOS使ってAlibabaCloudと繋がる事例を紹介    前提知識 本ガイドを理解するために、下記の前提知識が必要になります。</description>
    </item>
    
    <item>
      <title>DataV より桜前線のシミュレーション実現</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/product/datav/datav-sakura/</link>
      <pubDate>Mon, 30 Sep 2019 12:30:18 +0800</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/product/datav/datav-sakura/</guid>
      <description>Tags ： AlibabaCloud DataV Develop
目的 データ可視化の魅了の一つは、分かりづらい生データを生き生きで表現させて、誰でもすぐ分かるようにすることです。でも、データの表現力を豊かにするため、いつもプロのデザインナーに頼まないと行けないことで、普通のエンジニアにとってなかなか難しです。DataVの使命の一つは、まさにエンジニア達はこんな悩みから救えたいです。DataVを使えば、プロなデザインナーを頼らず、誰でも綺麗なDashboardを作れます。
今回はアリババ が11 月 11 日に行われた「独身の日」セールの際の使われたライブダッシュボードをベスに、簡単に日本の桜前線をシミュレーションすることを挑戦します。
実現したい効果は： * 日本地図上で、桜はいつどこで咲いてるか可視化したい * 日付ごとに桜前提の推移状況を動的に表現したい
上記実現するために、DataV上必要なwidgetは下記だけ： * タイムライン * 3D地図
 要注意：3D地図 Widget はDataVのエンタプライズ版しか使えないです。
 本ガイドの全体的な流れは下記の通りです。
   セクション Topic 説明     前提知識 DataV 基本紹介 DataV 基本機能の紹介   - Callback IDの紹介 DataV Callback IDの説明   - SpringBootの基本知識 SpringBootを使ってAPIサーバ構築の方法を紹介   準備作業 データの準備 必要な桜データと地図データの準備方法を紹介   - APIサーバの構築 APIサーバの構築方法を紹介   設定開始 DataVの設定 DataV各Widget設定方法の紹介   - 効果を検証 実現したシミュレーション効果を検証    前提知識 本ガイドを理解するために、下記の前提知識が必要になります。</description>
    </item>
    
    <item>
      <title>日本と中国のNW接続</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/network/jp-cn/</link>
      <pubDate>Mon, 30 Sep 2019 12:30:18 +0800</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/network/jp-cn/</guid>
      <description>目次  日本と中国のプライベートネットワーク接続（以下、日中接続）の解説の流れとなります。  本記事の狙い 日中接続パターン Alibaba Cloudであるメリット 日中接続の注意点 日中接続の構築例   
1. 本記事の狙い パブリッククラウドにおけるAlibaba Cloudの代表的な強みとして、中国との安定したネットワーク接続が挙げられます。ではAlibaba Cloudで具体的にどのようなサービスを用いれば日中接続を実現できるかを、既存の資料を交えて紹介いたします。
本記事を理解する前提として、Alibaba CloudのVPCとリージョンの知識が必要となるので、初見の方は以下のURLも併せてご確認ください。
VPCとは: https://jp.alibabacloud.com/help/doc-detail/34217.htm
リージョンとゾーン: https://jp.alibabacloud.com/help/doc-detail/40654.htm
 2. 日中接続パターン  Alibaba Cloud同士の接続 Alibaba Cloud以外のパブリッククラウドとの接続 オンプレミスの接続   Alibaba Cloud同士の接続 日中のシステムが共にAlibaba Cloud上で構築されている場合には、CEN (Cloud Enterprise Network) というサービスを用いるのが一般的です。
CENは、VPC（仮想ネットワークセグメント）に対して包括的なルーティング機能を提供します。その為「CENインスタンスの作成」と「CENインスタンスに対してVPCを紐付ける」の2ステップによって、日中VPC間でのプライベートIPアドレスによる通信が可能となります。ダイナミックルーティング等の複雑な設定は一切不要です。
ステップバイステップ手順 SBCloudドキュメント: CEN利用手順書
https://www.sbcloud.co.jp/entry/2018/08/01/cen-introduction/
Alibaba Cloudドキュメント: CEN利用手順書
https://jp.alibabacloud.com/help/doc-detail/59870.htm
本構成が当てはまるシステムの要件  データロスが許されないデータ通信 リアルタイム性が重要となるデータ通信 新規ビジネス展開に伴う新規システムの構築 既存のAlibaba Cloudリソースの利用 シンプルなインフラコードを実現したい  構成イメージ  Alibaba Cloud以外のパブリッククラウドとの接続 日中のシステムにおいて、他方がAlibaba Cloud以外のパブリッククラウド（AWSやAzure）上で構成されている場合、日中接続する為にIPSecを用いたVPNトンネルを構築するのが一般的です。
VPNトンネルの構築は以下の2ステップで実現出来ます。
 Alibaba CloudおよびAlibaba Cloud以外のアカウント、 この両方でVPNゲートウェイを作成する それぞれのVPNゲートウェイに、IPSec設定情報と対抗のゲートウェイ情報を入力する  VPNトンネルの構築後に、VPNトンネルを介した疎通を可能にする為、以下を実施します。</description>
    </item>
    
    <item>
      <title>DataV のデータ権限制御</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/product/datav/datav-develop-api-cookie/</link>
      <pubDate>Wed, 25 Sep 2019 12:30:18 +0800</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/product/datav/datav-develop-api-cookie/</guid>
      <description>Tags ： AlibabaCloud DataV API Develop
目的 普段の業務上では一つ Dashboard に対してユーザの権限によって表示されたデータが異なるという要望がよくあります。例えば会社の中で部長が見える社員の勤怠データ範囲は課長より広いはず。逆に課長は自分の部下以外の人の情報を見てはいけません。
BIツールの場合はDashboard機能以外はユーザ権限管理機能もあるため、上記要件を実現しやすいですが、DataVはただの Dashboard ツールだけなので、ユーザ管理機能がふくまれていません。こんな場合はどうのようにこの要望を実現できるでしょうか？
 実現案のキーワードは、DataV Dashboard をユーザ既存システムに埋め込んで、DataVのAPIデータソースの中でユーザ既存システムのCookie認証情報を利用すること。
 本ガイドでは、一つ簡単なサンプルを通じてDataVの実現方法を紹介させていただきます。
 本ガイドの全体的な流れは下記の通りです。
   セクション Topic 説明     前提知識 DataV のAPIデータソース利用 DataV のAPIデータソースの紹介   - CookieとCORS の基本知識 Cookieの紹介CORS制限の説明   - NodejsとExpressの基本知識 Expressを使ってAPIサーバ構築の方法を紹介   準備作業 APIサーバの構築 簡単な手順を紹介、細かいところを省略   - DataVの設定 DataV設定方法の紹介   実際の効果 効果を検証 実現したサンプルの効果を検証   ソースコードの説明 APIソースコードの説明 APIサーバ構築中の注意ポイントを説明    前提知識 本ガイドを理解するために、下記の前提知識が必要になります。</description>
    </item>
    
    <item>
      <title>DataV Widget 開発ガイド</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/product/datav/datav-widget-develop-guide/</link>
      <pubDate>Tue, 10 Sep 2019 12:30:18 +0800</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/product/datav/datav-widget-develop-guide/</guid>
      <description>Tags ： AlibabaCloud DataV Widget Develop
目的 DataV は AlibabaCloud のデータ可視化プロダクトとして日々進化しており、とても優れていますが、提供できる Widget が限られているため、一部特殊なニーズがあるユーザーに対応できない可能性があります。このため、DataVのプロ版（中国サイト基準の呼び方）では Widget 開発権限を開放し、DataV 固有の Widget の利用以外はユーザー自身も自由に開発できるようになります。
　DataV プロ版はユーザー自身の Widget を開発できるメリットがあることに加えて、開発された Widget を他人にも共有でき、中国サイトの MarketPlace で販売することもできるため、開発ベンダーにとっても DataV はデータ可視化ツールの魅了的なプラットフォームです。
本ガイドでは、いくつの簡単な Echarts ライブラリを DataV に取り込むためのサンプルを使用して、 DataV 開発版の使い方と Widget 開発のルールを紹介させていただきます。
 本ガイドの全体的な流れは下記の通りです。
   セクション Topic 説明     前提知識 DataV の基本知識 DataV の概要紹介と Widget の簡単な説明   - Echarts の基本知識 Echarts の概要紹介と Option の簡単な説明   - Nodejs の基本知識 NodeJS のパッケージと DataV widget の関係、および NPM コマンドの簡単な説明   準備作業 Token の取得と Group の作成 開発前に DataV 側で必要な準備作業   - ローカル環境構築 ローカルの開発環境の構築手順   開発ルール index.</description>
    </item>
    
    <item>
      <title>Sparkについて</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/003_what-is-spark/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/003_what-is-spark/</guid>
      <description>Apache Sparkとは &amp;nbsp; Apache Sparkはカリフォルニア大学バークレー校のAMP Labで開発されたオープンソースプロダクトです。Sparkは、大きなデータセットを処理および分析するための次世代のビッグデータ処理フレームワークです。 Sparkは、Scala、Python、Java、R言語による高レベルAPIサポート、Spark SQL、Streaming、機械学習のMLlib、グラフ処理用のGraphXなどを強力なライブラリを提供する統合処理フレームワークです。後にApache Software Foundationに寄付され、2014年2月24日にApacheトップレベルのプロジェクトになりました。
Sparkの概要 &amp;nbsp; SparkはHadoopのデータ処理フレームワークであるMapReduceの多くの処理制限問題を認識し、反復的でインタラクティブなアプリケーションを処理できる、より高速でより汎用的に利用できるデータ処理フレームワークとして開発されました。SparkのJobは、メモリ内の高速機能と高度なDAG（Directed Acyclic Graph）実行エンジンにより、同等のMapReduceジョブよりも10〜100倍高速に実行できます。データサイエンティスト、分析エンジニアからすれば、SparkはどのMapReduce処理よりも最も生産的な位置付けとなっています。
&amp;nbsp; Sparkは一見シンプルですが強力なAPIにより、非常に利用・汎用しやすくなっています。 Sparkは以下をサポートする統合プラットフォームを提供します。現在、Sparkはデータサイエンティスト、分析エンジニアにとって重要な存在となっています。ストリーミング、インタラクティブ処理、ETL、機械学習、バッチ処理、Delta Lake運用、container/Kubernetes、Function as a Serivce、超高速HTAPなど、幅広い分野へ広まっています。手法は別章にて紹介いたします。
Cluster Managers &amp;nbsp; Cluster Managersはアプリケーションのクラスタリソースを割り当て、管理をしています。Sparkは、Spark（Standalone Scheduler）、YARN、およびMesosに付属しているスタンドアロンのCluster Managersをサポートしています。またKubernetesをCluster Managersとして利用することも可能です。このテクニカルサイトにも手法を記載いたしますが、詳細についてはこちらを参照してください。
https://apache-spark-on-k8s.github.io/userdocs/running-on-kubernetes.html Sparkのアーキテクチャ &amp;nbsp; Sparkはコード内容（処理内容）をSparkアプリケーションタスクとして以下の画像のように複数のクラスターノードへ分散し処理することができます。すべてのSparkアプリケーションには、Driver ProgramにSpark Contextというオブジェクトがあります。Spark ContextはCluster Managersへの接続を意味しており、Sparkアプリケーションにコンピューティングリソースを提供します。Hadoop分散モードの上で実行となれば、マスターノードで実行、これがスレーブノードへ処理したいリソースを提供となります。
&amp;nbsp; クラスターに接続した後、SparkはWorker NodeでExecuterを取得します。その後、SparkはアプリケーションコードをExecuterに送信します。通常、アプリケーションはSparkアクションに応じて1つ以上のジョブを実行します。その後、各ジョブはSparkによって小さな有向非周期グラフ（DAG）に分割されます。その後、各タスクは分散され、実行のためにワーカーノード全体のExecuterに送信されます。各Sparkアプリケーションは、独自のExecuterのセットを取得します。異なるアプリケーションのタスクは異なるJVMで実行されるため、Sparkアプリケーションは別のSparkアプリケーションと干渉することはないです。（＝処理内容が重複、コンフリクトすることがない構造）これはHDFSやS3などの低速の外部データソースを使用しないと、Sparkアプリケーション同士がデータを共有することは難しいことを意味します。一方、AlibabaCloudのSparkはJindoFSを使うと、ワーカーノードがOSSら外部データソースとマルチ接続し分散処理されるため、OSSに対してデータ共有をより速く、かつ簡単に読み込み、書き込みすることができます。JindoFSや手法は別章にて紹介いたします。
Spark on YARN &amp;nbsp; YARNはHadoopベースのCluster Managersです。YARNでSparkアプリケーションを起動するためには2つの方法があります。
Cluster Mode &amp;nbsp; Cluster Modeの場合、Driver Program は YARNによってアプリケーションを管理、実行されます。そのため、クライアントはアプリケーションの実行に影響を与えることなく終了できます。
アプリケーション、またはSpark Shellをクラスタモードで起動するには以下のコマンドになります。
spark-shell --master yarn --deploy-mode cluster spark-submit --class myPath.myClass --master yarn --deploy-mode cluster</description>
    </item>
    
    <item>
      <title>コンテナイメージ作成・管理</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/container/03/image-management/</link>
      <pubDate>Tue, 13 Aug 2019 16:20:40 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/container/03/image-management/</guid>
      <description>以下の区分により、コンテナを活用したAlibaba Cloudにおける開発手法を紹介いたします。
 開発環境 コンテナイメージの作成・管理 コンテナデプロイ管理 ログ管理とモニタリング  本項目では、 コンテナイメージ作成・管理 に焦点を当てて、インターネットと接続しないプライベート環境における手法とインターネット上で利用可能なパブリックサービスを用いた手法の2種類を紹介します。その後、Alibaba Cloudにおける推奨を紹介します。
コンテナイメージ管理  プライベート環境における手法 パブリックサービスを用いた手法 Alibaba Cloudにおける推奨  プライベート環境における手法 プライベート環境（外部公開していないサーバ）にてコンテナをビルドする時には、まずコンテナイメージをビルドするスクリプトを自身で作成します。その後、パイプラインツールを実行するサーバを作成してその上で、「コードソースの変更を検知して、ビルドスクリプトを実行、ビルドされたコンテナイメージをイメージリポジトリにプッシュする」仕組みを実装するのが一般的です。
パイプラインツールはJenkinsが無償で利用でき、最も広く利用されています。パブリックサービスであるGitLabCIやCircleCIの有償パッケージを、プライベート環境に導入する事も可能です。コンテナイメージリポジトリは有償のDocker Trusted RegistryやGitlab Enterprise Registryが利用可能です。
 イメージビルド  Jenkins/JenkinsX GitLabCI CircleCI Enterprise  イメージレジストリ  Docker Trusted Registry Gitlab Enterprise Registry   パブリックサービスを用いた手法 パブリックサービスを用いてコンテナイメージをビルドする時も、自前でビルドスクリプトを作成する点は変更ありません。 ただ独自の環境変数やパイプライン処理が事前に提供されている為、Jenkins等のパイプラインツールよりも簡素的に実装できる事が多く、何よりサーバの管理が不要な為、運用における利便性に優れていると言えます。
 イメージビルド  GitLabCI CircleCI TravisCI  イメージレジストリ  Dockerhub Gitlab Registry   Alibaba Cloudでの選択肢 Alibaba CloudではContainer Registryというイメージサービスの機能の一つとしてコンテナのビルドが実行できます。 Container RegistryはGithub/Gitlab/Bitbucketのソースコードを読み取り、自動でビルドを実行して イメージをリポジトリにプッシュします。特徴的なのは他のサービスでは必要となるビルドスクリプトの作成や YAMLファイルが一切不要で、GUI操作のみで一貫してビルドからプッシュまでを設定できる点です。 この為、Container Registryは有用な選択肢の一つと言えるでしょう。</description>
    </item>
    
    <item>
      <title>料金体系</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/general/pricing/</link>
      <pubDate>Thu, 01 Aug 2019 12:30:18 +0800</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/general/pricing/</guid>
      <description>Tags ： AlibabaCloud Price Bill
本文の概要は下記のとおりです。
  Alibaba Cloud 料金の基本的な考え方の紹介 Alibaba Cloud 課金体系の紹介 Alibaba Cloud お支払い関連の紹介 代表的なプロダクトの料金体系の紹介  初めに  本文の目的は、Alibaba Cloud の課金ルールや料金計算方法などを紹介し、お客様のサービスにおける今後のコスト管理と最適化に役立つように、 AlibabaCloud の料金体系を理解してもらうことです。  基本概念  まず、買い物における一般的な料金関連の基本概念をいくつか紹介します。
キーワード１：レンタル 一般的に、買い物は買った物に対する所有権の有無で２種類に分けられています。
 所有権あり：お金を払った後、物の所有権がお客様に移るケース。購入後のすべての権利をお客様が所有する。例：りんごを買った後、自分で食べるか、捨てるか、または他人にあげるか、どのように処分しても構いません。
 所有権なし：お金を払った後、物の所有権ではなく、一定期間内の使用権のみをお客様が所有するケース。例：ホテルの部屋に一週間泊まる場合、この一週間は部屋のものを使用する権利がありますが、破損してはいけません。また、一週間後にこの部屋から出なければなりません。
  クラウド上の商品は、基本的にはお客様はデータセンターのリリース（CPU、DISK、NetWork）やアプリケーション（API）をある時間帯でレンタルし、自身のビジネスを行うという形です。なので、クラウド上料金の設定は基本的にはレンタル式の考え方です。
キーワード２：前払いと後払い 買い物の際、お金を支払うタイミングによって、課金方法は前払いと後払いの 2 種類に分けられています。
 前払い：サブスクリプション或いはプリペイド（Prepaid）という名前もよく使われています。支払いが行われた後にリソースを使用できます。これは一般的によく使用される支払い方法です。 後払い：従量課金或いはポストペイド（Postpaid）という名前もよく使われています。料金は実際の使用量に基づいて後で支払います。リソースはいつでも作成およびリリースできるため、とても柔軟性の高い支払い方法です。  2 つの課金方法は項目ごとにそれぞれメリットとデメリットがあります。比較の詳細は、下記表をご参照ください。
   比較項目 サブスクリプション 従量課金     支払いタイミング 前払い 後払い   決済サイクル 週／月／年 １時間   柔軟性 低 高   平均単価 低 高   利用シーン 長時間利用 短時間利用   料金滞納リスク なし あり   すぐリリース 不可 可能    Alibaba Cloud はサブスクリプションと従量課金の両方をサポートしています。</description>
    </item>
    
    <item>
      <title>サンプルプロジェクトの作成</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/03/sample-project/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/03/sample-project/</guid>
      <description>&amp;nbsp; ここまででTerraform のインストール方法を学びました。それではサンプルプロジェクトを作成します。簡単なWebサーバを立ち上げながら、Terraformの流れや中身を確認します。 1. ディレクトリ・ファイル構成 &amp;nbsp; Terraformのファイルの拡張子は *.tf です。実行時、同じディレクトリの *.tf ファイルがマージされますので、基本は以下3ファイルに分けてそれぞれの用途・目的に応じた記載・運用がベターです。
main.tf … モジュールが内包するリソース、データソースなどの定義 outputs.tf … モジュールが出力するAttributeの定義 variables.tf … モジュールが受け取る変数の定義  main.tf には どのプロパイダを使うかを記載します。 階層化は任意ですが、.tfから別のフォルダの.tfに記載されてる変数を取り出すためにルートディレクトリを指定することがありますのでそこは注意が必要です。apply (=実行) にて分離実行することも可能です。 例えば以下のようにプロダクトサービス毎にフォルダを作成し、それぞれのリソースを作成しても、最終的には一つへまとめれます。
├── main.tf ├── output.tf ├── variables.tf │ ├── region │├── VPC ││├── main.tf ││├── output.tf ││└── variables.tf ││ │├── ECS ││├── main.tf ││├── output.tf ││└── variables.tf ・ ・ ・  &amp;nbsp; RAMなど他者へ渡したくない情報がある場合、別途設定ファイル（ confing.tfvars など）へ記載し、実行時は -var-file引数で 設定ファイルを読み取り実行することができます。
├── main.tf ├── output.tf ├── variables.</description>
    </item>
    
    <item>
      <title>負荷分散</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/web-application/03/loadbalancer/</link>
      <pubDate>Mon, 13 May 2019 16:20:40 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/web-application/03/loadbalancer/</guid>
      <description>以下の区分により、Alibaba Cloudを活用したWebアプリケーション構築手法を紹介いたします。
 名前解決 負荷分散 Web/APサーバ データベース/キャッシュ  本項目では、Alibaba Cloudの負荷分散に関するサービスの基本仕様と設計ポイントを紹介します。
負荷分散  対象サービス 基本的な仕様 設計のポイント 参考リンク一覧  対象サービス Webアプリケーションにおいて負荷分散を実現するサービスを3つ紹介します。ひとつはロードバランサーの役割を担うServer Load Balancerです。もうひとつは、jpegやcss等の静的ファイルを公開する際に用いるObject Storage Serviceです。最後に、コンテンツデリバリーサービスとして機能するAlibaba CDNです。以上の3つのサービスを活用する事で、可用性の高いWebアプリケーションを実現します。
基本的な仕様 Server Load Balancer (SLB)  SLBインスタンスを作成する際、以下のパラメータを入力します。
 インスタンス名
 スペック
 インターネット公開かイントラネット公開か
 アベイラビリティゾーンの設定
 プライマリゾーンとバックアップゾーン
   バックエンドに複数のECSからなるサーバグループを指定、ヘルスチェックを有効化して、疎通確認します。
 SLBインスタンスのIPアドレスもしくはCNAMEを、A/CNAMEレコード登録してドメインとして公開します。
 SLBインスタンスに付与されたIPアドレスは静的であり、動的変更されません。
 証明書を登録して、SSLアクセラレータとして機能させます。
 WebSocketやHTTP2.0、セッション維持の有効・無効を指定できます。
 物理ロードバランサと同じようなセキュリティルールを設定してアクセス制御します。同ルールには以下が含まれます。
 アクセスの許可もしくは禁止（ホワイトリストとブラックリストの双方として機能する）
 プロトコルとポート番号
 1~100までの優先番号をつけ、数字が小さい方から優先適用
     Object Storage Service (OSS)  バケットを作成して、その配下にファイルをアップロードして利用します。</description>
    </item>
    
    <item>
      <title>HDFSとは</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/004_what-is-hdfs/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/004_what-is-hdfs/</guid>
      <description>HDFSについて &amp;nbsp; 別の章にてHDFSについてを軽く説明いたしましたが、本章はこれについてもう少し詳しく説明します。 HadoopはHDFS（Hadoop Distributed Filesystem)と呼ばれる分散ファイルシステムを利用しています。HDFSは非常に大きなファイルを保存、処理、抽出するために設計されたファイルシステムで、多数のコモディティハードウェア（一般販売されてるどのハードウェア）によって構成されるクラスタで動作します。
 非常に大きなファイルを設計  数PB〜EBに及ぶ設計 HDFS上に構築されたKey-Value-Store  ストリーミング型のデータアクセス  「書き込みは一度、読み出しは何度も行う」といった効率的なデータ処理パターンで設計  コモディティハードウェア  一般人でも購入可能なハードウェアでクラスタを構成    &amp;nbsp; HDFSクラスターは、クラスター内のノードごとに1つのNameNode（ネームノード）と複数のDataNode（データノード）で構成されます。NameNodeは、すべてのHDFSメタデータ（属性情報、構成情報、容量、カテゴリライズetc）を記録、管理します。いわゆるHDFSクラスタのリポジトリの位置付けです。NameNodeは、マスターサーバとスレーブサーバの構成で機能し、NameNodeによってファイルシステムを全体管理するため、マスタサーバ/ネームノードを通さずにDataNodeのファイル取得へのアクセスを規制します。応用としてケルベロス認証があります。ケルベロス認証は別の章にて記述します。
&amp;nbsp; NameNodeに入ってくるファイルは1つ以上のblockに分割され、それぞれのDataNodeに保存されます。NameNodeはファイルやディレクトリのオープン、クローズ、名前変更などのファイルシステム操作をします。DataNodeによって送信されたハートビートとブロックレポートからDataNodeへのブロックのマッピングを決定します。DataNodesは、読み取り/書き込み要求を実行し、NameNodeがコマンドを要求した場合にのみ、ブロック作成、ブロック削除、およびブロック複製を実行します。
&amp;nbsp; HDFSはデータ保存をメインとして利用しますが、HBaseやKudu、他のNoSQL、Spark、tensorflowのような他の様々なHadoopエコシステムに利用する場合があります。様々なユースケースに応じてHDFSの種別、圧縮形式、ストレージ形式を考慮する必要があります。これは様々なHadoopエコシステムに依存します。以下、本章ではHDFSのファイル形式、圧縮戦略、スキーマ設計などについて説明します。
HDFSの設計 &amp;nbsp; 上記、HDFSのアーキテクチャを説明しました。HDFSはあくまでも大規模なビッグデータに対応するためのファイルシステムの故、以下のメリットとデメリットがあります。
   得意分野 不得意分野     PB〜EBと非常に大きなファイルを処理 数KBなど大量の小さなファイルを処理   大容量のデータを高速でKVS処理することができる 高スループットを出すためにレイテンシが犠牲になってる   「書き込みは一度、読み出しは何度も行う」というストリーミング型のデータアクセス 複数ユーザによるHDFS更新処理が不可    
&amp;nbsp; しかし、このHDFSの不得意分野はHadoopエコシステムのHBase、そしてKuduによって払拭されています。KuduはHDFSをストレージとした、低レイテンシで高スループット、複数ユーザによる処理が可能なBigDataのRDBMSが可能となるストレージの位置付けです。本章はHDFSの基本的なことに集中するため、HBaseやKuduは別の章にて記述いたします。
HDFSのPartitionについて &amp;nbsp; Hadoopストレージレイヤでデータを管理するため、HDFSはフォルダ構造になっています。大量のファイルをhdfs.file.block.sizeで分割し保存してるため、区別ができるよう、それぞれのフォルダをパーティションとして保存されます。
HDFSのファイル形式について &amp;nbsp; HDFSは様々なデータ形式を持っています。Parquetにorc、csv、json、AlibabacloudのオリジナルのaliORC、などがあります。
&amp;nbsp; HDFSをcsvやtextファイルとして保存、処理すること可能ですが、HiveやSparkなどのMapReduce、ImpalaなどMPPら分析処理が遅くなります。理由として、csvやtextファイルなど生データの場合、メタ情報が担保できないことや、型変換のオーバヘッドが発生してしまうことから、HDFSのデータ量が多ければ多いほど分析処理クエリの性質上、フィールド名を認識する流れなどにて処理遅延、I/O負荷が発生してしまいます。
&amp;nbsp; また、XMLやJSONをHDFSに変換することは可能ですが、開始タグと終了タグがないため、分割することが難しいのでHadoopそのものでHDFSにすることはできません。代わりの方法として、SparkもしくはHiveでParquet/Avro/Sequenceなどの形式に変換する必要があります。
&amp;nbsp; 画像/動画などのバイナルファイルは基本的にfile.block.sizeごとにSequenceなどのコンテナ形式で保存されます。逆に100GBとかあまりにも大きいバイナリファイルであれば、ブロック固定長の関係とディスクの転送レートからしてそのまま保存することが望ましいです。
&amp;nbsp; 他、HadoopのHDFSとして様々なファイル形式があります。特徴、列指向、様々なHadoopエコシステム、比較表を作成しましたので、こちらを参照いただければ幸いです。</description>
    </item>
    
    <item>
      <title>コンテナデプロイ管理</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/container/04/deploy-management/</link>
      <pubDate>Tue, 13 Aug 2019 16:20:40 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/container/04/deploy-management/</guid>
      <description>本記事では、コンテナデプロイ管理について紹介いたします。
 開発環境 コンテナイメージの作成・管理 コンテナデプロイ管理 ログ管理とモニタリング  コンテナデプロイ管理では、開発環境と本番環境の２点に焦点を当てて紹介します。その後、Alibaba Cloudにおける推奨を紹介します。
コンテナデプロイ管理  開発環境 本番環境 Alibaba Cloudでの選択肢  開発環境 開発環境の場合ではコードの変化に伴って、コンテナイメージを作成、環境変数を伴ってデプロイする必要があります。 その際には各種IDEのプラグインよりdocker buildを実践して、コンテナイメージを作成して、docker-composeを使って他のコンテナとの連携する方法が最もシンプルです。また、本番環境でKubernetesを利用する場合には、Minikubeやmicrok8sを用いて、Kubernetes環境をローカルの開発環境に再現する事も有用です。
 IDEのプラグイン docker-compose Minukube microk8s scaffold  本番環境 本番環境では、可用性を保つ為にサーバでクラスターを組み、冗長性を保った上でコンテナを動作させる事が一般的です。 簡易的な機能のみであればNomad、フルスタックな機能が必要であればKubernetesが利用できます。
 Nomad Kubernetes  Alibaba Cloudでの選択肢 Alibaba Cloudでは現在のデファクトスタンダードと言えるKubernetesを３種類の形で提供しています。 Kubernetesは大きくMaster nodeとWorker nodeの2種類のホストで構成され、それぞれをユーザが管理するか Alibaba Cloudの任せるかという違いがあります。
   種類 Master nodeの管理 Worker nodeの管理     Dedicated ユーザ ユーザ   Managed Alibaba Cloud ユーザ   Serverless Alibaba Cloud Alibaba Cloud    Dedicatedは既存でKubernetesを利用していて、その設定を引き継ぎたいなど、より細かい設定をしたい要件がある時、 インフラの細かい設定が不要でとにかく使いたい場合はServerless、その中間の選択肢がManagedとなります。</description>
    </item>
    
    <item>
      <title>サンプルプロジェクトの実行</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/04/run-terraform/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/04/run-terraform/</guid>
      <description>&amp;nbsp; 前章は 簡単なWebサーバを立ち上げるというサンプルプロジェクトを作成しました。今章はサンプルプロジェクトを実行しつつ、Terraformの流れや中身を確認します。
Terraformの実行は非常にシンプルです。以下図のようにterraform initから始まり、terraform play、terraform applyでリソース作成を実行します。

1. terraform init &amp;nbsp; コードを書いたら「terraform init」コマンドを実行します。このコマンドはTerraformの実行に必要なプロパイダーのバイナリをダウンロードしてくれます。「Terraform has been successfully initialized!」と表示されていれば作業ディレクトリ構成的にOKです。
$ terraform init Initializing provider plugins... ・・・ Terraform has been successfully initialized!  
2. terraform plan 次は「terraform plan」コマンドです。 RAMなどの情報を別途設定ファイル confing.tfvars へ記載した場合は以下のコマンドで実行します。
$ terraform plan -var-file=&amp;quot;confing.tfvars&amp;quot; Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage.</description>
    </item>
    
    <item>
      <title>Web/APサーバ</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/web-application/04/web-ap/</link>
      <pubDate>Mon, 13 May 2019 16:20:40 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/web-application/04/web-ap/</guid>
      <description>以下の区分により、Alibaba Cloudを活用したWebアプリケーション構築手法を紹介いたします。
 名前解決 負荷分散 Web/APサーバ データベース  本項目では、Alibaba CloudのWeb/APサーバに関するサービスの仕様と設計ポイントを紹介します。
負荷分散  対象サービス 基本的な仕様 設計のポイント 参考リンク一覧  対象サービス Web/APサーバとして用いるサービスは、仮想サーバであるElastic Compute Serviceを用いるのが最も一般的です。 Autoscalingを実装します。加えてContainerServiceもアプリケーション環境として活用されており、こちらも紹介します。
基本的な仕様 ECS  ECS  OSには、Fedora、Cent、Ubuntu、Windowsに加えて、独自のAliyunOSも利用できます。 ログはCloudMonitorから確認できます。 セキュリティグループでインバウンドアウトバウンドを設定します。 ECSインスタンス自体にAlibaba CloudのSaaS利用の権限をRAMより付与します。 VNCからアクセス可能です。 メタ情報はcurl で取得できます。 Webを公開していると、セキュリティアラートを能動的に検知します。 インスタンス削除をリリースと呼び、時間指定リリースが可能です。     Auto Scaling  インスタンスの最大数・最小数、インスタンスをデプロイするVPC、インスタンスの削除ポリシーを設定して利用します。 最初に「スケーリンググループ」を作成してスケーリングに関する設定を行い、次に「スケーリング設定」を作成して、スケールするECSの設定を紐付けます。 既存のインスタンスを、オートスケーリンググループに追加することも可能です。    Container Service  Kubernetesを利用して、Dedicated Kubernetes・Managed Kubernetes・Serverless Kubernetesが利用できます。 フロントエンドとしてSLBを連携作成します。 バックエンドはデータベースを指定してホワイトリスト形式でアクセス許可する事で疎通させます。 Kubernetesで利用可能な主要モジュールをコンソールから実施できます。  ステートフルコンテナの起動 バッチコンテナの起動  Container Registryと併用する事で、Github/Gitlab/BitbucketからシームレスにKubernetes環境にデプロイ可能です。 Log ServiceやCloudMonitorといったAlibaba Cloudのサービスとの他に、Prometheus＋Grafanaを用いたモニタリングも推奨されています。     設計ポイント ECS  時間が中国語。 新規インスタンス作成時にパスワードか秘密鍵のいずれかを指定できますが、デフォルトではどちらも設定されずに作成されます。 サブスクリプションする場合には、EBSディスクも一緒に購入できます。 セキュリティグループのルール設定は、許可・禁止を選択でき、優先度設定によって管理します。 同一セキュリテイグループに紐付くインスタンス間の通信は全許可されます。 AliyunOSの場合、NginxをパッケージインストールしようとするとTerwayがインストールされます。    Auto Scaling  スケーリング設定の代わりに起動テンプレートを使用すると、既存のすべてのスケーリング設定が自動的に無効になります。 台数の細かく調整する時には、スケーリングルールを作成・実行することで、スケーリングアクティビティをトリガーできます。    Container Service  リージョンやアカウントの種類によって、Container Registryが利用できない等一部利用可能なサービスに違いがあります。 DockerfileにENVとして記載された環境変数がそのままコンソールの環境変数項目にもパースされるので、環境変数は docker-entrypoint.</description>
    </item>
    
    <item>
      <title>YARNとは</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/005_what-is-yarn/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/005_what-is-yarn/</guid>
      <description>YARNについて &amp;nbsp; 本章ではYARNについてを説明します。YARNとは以下の通りになります。
 YARNはYet-Another-Resource-Negotiatorの略称 Hadoopエコシステムのためのリソース管理マネージャ サーバ数台のメモリやCPUなどリソース要求ハンドリングなど、リソースオーケストレーションを行う分散サービス   こちらについてもう少し詳しく説明します。 YARNファミリーのそれぞれの役割、およびHadoopクラスタの位置付けを図で示すとこのようになります。
YARNファミリー  ResourceManager  クラスタのリソースを監視、管理 ワーカーノードにタスクを割当  NodeManager  様々な処理をワーカノードに起動、管理   Application Master  YARNクラスタ上のタスク・コンテナを全てまとめるTask 司令塔としてマスタサーバに実装  コンテナ  Taskを処理するリソースの単位。 voreリソースとメモリリソースを保持してる &amp;gt;vcoreはCPUの使用率のようなもの。メモリはコンテナ専用の仮想メモリ。バイト数として扱う  Task  コンテナ内で処理するプロセス コンテナのリソースはTaskに割当 クライアントのコードはTaskで実行  YARNを使ったアプリケーション実行の流れについて &amp;nbsp; 上記説明通り、YARNを利用するとResourceManager、NodeManagerの配置が実施されます。このような体制でクライアントからアプリケーションを起動してみます。すると以下の流れでYARN処理が実施されます。
 クライアントにて MapReduce、Sparkなどアプリケーションを実行 マスタサーバ/ネームノード側でResourceManagerが受け取り、AppllicationMasterへ仲介指示 ApplicationMaster側がアプリケーションを実行するためにはどれほどかのリソースを確認（＝DAG） ApplicationMaster側がResourceManager側へ処理に必要なコンテナ（単位）の割当を依頼 ResourceManager側はコンテナ（単位）を受け取り、NodeManagerそれぞれへリソース配布 NodeManagerにて処理に必要なタスクをそれぞれ実施 NodeManagerにて処理が行き詰ったり問題が出たらResourceManagerへ通知し、その分のコンテナ(単位）を別のNodeManagerへ割当（またはコンテナ(単位)を増やすなど調整） NodeManagerで持ちTask処理が終わればResourceManagerへ通知 全てのNodeManagerの処理が終われば、アプリケーション結果をクライアントに返してアプリケーション終了  TensorFlow on YARN &amp;nbsp; AlibabaCloud E-MapReduceにTensorFlow on YARNがあります。こちらはApache Hadoo上で分散型機械学習を運用するために開発されたフレームワークです。YARNのリソース管理やコンテナ構築などのタスク処理を応用した、TensorFlowのジョブをHadoopクラスタに割り当てて分散処理を実現します。同時に、スケジューリングや種類に応じたリソース要求処理、メモリの割当調整ができます。
より詳しくはこちらのドキュメントを参照してください。 * Native Support of TensorFlow on Hadoop https://engineering.</description>
    </item>
    
    <item>
      <title>ログ管理とモニタリング</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/container/05/monitoring/</link>
      <pubDate>Tue, 13 Aug 2019 16:20:40 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/container/05/monitoring/</guid>
      <description>本記事では、ログ管理とモニタリングについて紹介いたします。
 開発環境 コンテナイメージの作成・管理 コンテナデプロイ管理 ログ管理とモニタリング  ログ管理とモニタリングでは、OSS/Enterprise製品とパブリックサービスの２点に焦点を当てて紹介します。その後、Alibaba Cloudにおける推奨を紹介します。
ログ管理・モニタリング  OSS/Enterprise製品の活用 パブリックサービスの活用 Alibaba Cloudでの選択肢  OSS/Enterprise製品の活用 Container環境においてアプリケーションログとインフラログを対象にして、ログ管理・集計の製品と、それらをGUIとして可視化する製品の組み合わせがあります。
 Fluentd + Elasticsearch + Kibana
 Prometheus/Grafana Loki/Grafana  パブリックサービスでの活用 クラウド型のサービスとしてDatadogやNew Relicを活用するのも広がっています。これらはパブリッククラウドの読み取り権限のアクセスキーを登録する事で、パブリッククラウドインフラ全体のログを収集・可視化する事ができます。また、APMの機能も提供しており、アプリケーションログも並行して取得する事ができます。
 Datadog New Relic  Alibaba Cloudにおける選択肢 Alibaba Cloudにおいてコンテナ内のログとコンテナ外のログを確認する事があります。コンテナ内のログはLogServiceを有効化して、同ログをObject Storage Service(OSS)に蓄積する形が一般的です。ECSやKubernetes等のサーバに関するメトリックはCloudMonitorで確認する事が出来ますが、インフラ全体のログはPrometheusを利用して、Grafanaで可視化する形が推奨されています。また、パブリックサービスの中ではDatadogがAlibaba CloudとのIntegrationを提供しており、同サービス内で一括監視する事も可能です。
アプリケーションログ - LogService - Datadog APM インフラログ - CloudMonitor/Grafana - Datadog Alibaba Cloud Integration ログ全般 - Prometheus/Grafana
参考リンク一覧    タイトル URL     Prometheusモニタリングシステムのデプロイ https://jp.</description>
    </item>
    
    <item>
      <title>Terraform文法について</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/05/program-syntax/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/05/program-syntax/</guid>
      <description>&amp;nbsp; 前章は 簡単なWebサーバを立ち上げるというサンプルプロジェクトを実行しました。うち、Terraformには様々な記載文法がありますので、把握した方がいい部分だけ説明します。

1. Configuration Syntax &amp;nbsp; Terraformのコード構成要素、コードの構成文の書き方です。Terraformの利用ガイドラインに沿って記載してみてください。Terraformのバージョンによっては書き方が異なる場合がありますので、注意が必要です。
# project_nameを宣言 variable &amp;quot;project_name&amp;quot; { } /* alicloud_vpcを設定 変数project_nameを呼び出す */ resource &amp;quot;alicloud_vpc&amp;quot; &amp;quot;vpc&amp;quot; { name = &amp;quot;${var.project_name}-vpc&amp;quot; cidr_block = &amp;quot;192.168.1.0/24&amp;quot; }   単一行コメントは#をつけます。 複数行コメントは/*と*/で囲みます。 文字列は二重引用符で囲みます。 文字列は${}を使って他の構文や値を補間できます。 ${var.foo}。 数字は10進数で扱います。数字の前に英数字を付けると、例えば0xでも16進数として扱われます。 ブール値が使え、true、falseのどれかになります。 プリミティブ型のリストは角括弧（[]）で作成できます。例：[&amp;quot;foo&amp;quot;, &amp;quot;bar&amp;quot;, &amp;quot;baz&amp;quot;] マップは中括弧（{}）とコロン（:） で作成できます。例：{ &amp;quot;foo&amp;quot;: &amp;quot;bar&amp;quot;, &amp;quot;bar&amp;quot;: &amp;quot;baz&amp;quot; } キーが数字で始まっていない限り、キーでは引用符を省略できます。その場合は、引用符が必要です。単一行マップでは、キーと値のペアの間にコンマが必要です。複数行マップではキーと値のペアの間の改行で十分です。  他、構成文の書き方もありますが、ひとまずは上記のを抑えれば大抵問題ないです。

2. Interpolation Syntax &amp;nbsp; 変数・関数・属性など、コード補充機能です。
 ユーザ文字列変数 var.接頭辞とそれに続く変数名を使用します。たとえば${var.foo} で foo変数値を補間します。
 ユーザーマップ変数 構文はvar.MAP[&amp;quot;KEY&amp;quot;]です。たとえば${var.amis[&amp;quot;us-east-1&amp;quot;]} でマップ変数us-east-1、内キーの値amisを取得します。
 ユーザリスト変数 構文は${var.</description>
    </item>
    
    <item>
      <title>データベース</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/web-application/05/database/</link>
      <pubDate>Mon, 13 May 2019 16:20:40 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/web-application/05/database/</guid>
      <description>以下の区分により、Alibaba Cloudを活用したWebアプリケーション構築手法を紹介いたします。
 名前解決 負荷分散 Web/APサーバ データベース  本項目では、Alibaba Cloudのデータベースに関するサービスの基本仕様と設計ポイントを紹介します。
データベース  対象サービス 基本的な仕様 設計のポイント アーキテクチャ図  対象サービス Relational DatabaseとしてApsara for RDS、NoSQL DatabaseとしてApsara for MongoDBを利用する事が出来ます。 &amp;ldquo;Apsara&amp;rdquo;という名前はAlibaba社内でのAlibaba Cloudを指す為、その名残として名称となります。
基本的な仕様 Apsara for RDS  リードレプリカの追加
 ディスク消費量のコンソールからの確認
 メンテナンス時間の設定
 アクセスホワイトリストの設定
 コンソールからパラメータの書き換え可能
 文字コードはデータベースの仕様に準拠
    Polar DB  2019年8月末時点でジャカルタリージョンのみ利用可能です。
    Apsara for MongoDB  レプリカセットかシャーディングかの選択をした後に、リージョン、VPC、スペック、MongoDBバージョン、レプリカ/シャーディング数、パスワードを入力して作成
 作成後には主に以下の設定が可能となります。
 バックアップ・リカバリ
 リソース監視
 アラームルール設定
 パラメータ設定</description>
    </item>
    
    <item>
      <title>DWHには何が必要か</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/006_what-is-required-for-dwh/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/006_what-is-required-for-dwh/</guid>
      <description>DataLake、DWH、OLTP、OLAPについて &amp;nbsp; 本章ではDataLake、DWH、OLTP、OLAPについてを説明します。
 DataLakeとは、様々なデータを一点集約したデータのプールです。
 DWHとは、Data Ware House、二次三次利用できるよう処理済みのデータ基盤（テーブルたち）のことです。
 OLTPとは、Online Transaction Processing、オンライントランザクション処理のことです。
 OLAPとは、Online Analytic Processing、オンライン分析処理のことです。
  &amp;nbsp; BigDataを成功するためには、前章で記述した通り、BigDataから新しいビジネス意思決定に必要なデータや価値を発掘する必要があります。その鍵としてDWH構築の設計、基盤構築が必須となっています。以下、DataLakeとDWHの違いを記載します。
    DataLake DWH     構造 未使用データ 処理済み、過去データと連結したデータ   目的 外部データソースから集約する場所 分析基盤として利用する場所   利用ユーザ 外部データソース 分析エンジニア、データサイエンティスト、機械学習    &amp;nbsp; BigData以前にMySQLやOracleなどリレーショナルデータベースでデータが肥えた時、古いデータを捨てたらいいのではないか？という意見がありますが、答えはNoです。
&amp;nbsp; 過去の古いデータも含めてこれらはビジネス上必要な資産（財産）情報なので、これを捨てることなく蓄積し、これが次の世代や今後のビジネスへ結びつける必要があります。そうすることで、ビジネス上意思決定アプローチ、例えば製造業で過去データから異常製品を検出したり、店舗の売上が下がってる時は過去データと比較して原因追求することができます。同時に、ビジネスへ活かすことでBigDataに対する設備投資の回収も見込めます。MySQLやOracleなどリレーショナルデータベースの場合はデータの範囲が限られてるため、少ないストレージ要領で分析メイン利用であれば設備投資回収が難しいです。
&amp;nbsp; DWHを設計する上で特に意識したいことは以下の３点になります。
 データ収集、加工、処理が簡略化できる
 容量を気にしない、長期的なデータ分できができる
 テーブル一本化（ファクトテーブル）で大規模加工処理や高速検索が可能
  この３点を満たせば、DWHは分析基盤としても非常に有利になりますので、これらを意識して構築いただければと思います。
データ分析業務のミッション &amp;nbsp; データ分析業務のミッションとして、サービスを継続、成功へ導くために、様々なLogをDWHへ収集、蓄積し、KPI、データの見える化を実現、分析し次のステップへ進める様に取り組みます。図の様なワークフローになります。こちらも「収集・蓄積」、「収集・加工」、「分析」ででデータ容量に注目してください。
上記、外部データからDataLakeへ収集、蓄積し、これを集計・加工、そして分析へといったワークフローがありますが、数千万レコードとか大規模データとなるとそう簡単には行かないです。そのために、OLTP、OLAPのアーキテクチャを持ったhadoopエコシステムでの処理が必要になります。
・OLTPは更新系（生成/挿入/更新/削除）、１行単位のスキャン
・OLAPは分析処理、select参照、フルスキャン
総じて、DHWがPB〜EB級でも更新できる、TB級の大規模データの分析難易度が鍵となります。</description>
    </item>
    
    <item>
      <title>Dockerについて</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/06/docker/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/06/docker/</guid>
      <description>&amp;nbsp; 前章までは Terraformのインストール方法、Terraformの文法、実行方法を説明しました。しかしこれらはTerraform v0.11.13前提での話なので、Terraformのバージョンが違うことで挙動が異なってしまうこともあります。Terraformでよく使うメソッドが急に廃止、、というのもよくあります。それを防ぐためにdockerを使ったインストール、利用する方法があります。dockerはパッケージングを行うための技術です。
*注：Terraformのバージョン食い違いは基本的にtfenvでカバーできます。詳しくはインストールを参照してください

1. dockerについて &amp;nbsp; dockerはOS・ミドルウェア・ファイルシステム全体をイメージという単位で取り扱い、まるごとやりとり出来るツールです。また、イメージの配布やバージョン管理も可能です。メリットとして、手軽に同じ環境を何人のユーザ・ユーザ・他のマシンでも手に入れることができ、即座に同環境を再現（ CI (Continuous Integration) 継続的インテグレーションと CD (Continuous Delivery) 継続的デリバリー ）することができます。 また、dockerはTerraformで大きく３つの役割があり、Terraformのインストールや実行環境の再現、各種リソースの接続設定、docker Imageを使った既存のプロダクトリソースをそのまま導入することが可能です。（docker Imageとは、dockerコンテナを作成する際に必要となるファイルシステムです。）

2. dockerのTerraform位置について &amp;nbsp; Terraformによるdockerの利用は大きく3パターンあります。他の便利な役割もありますが、ここは以下３つに絞って紹介します。
 1.Terraformのバージョン違いなど環境差分を抑えつつ実行する場合 2.Terraformで新規作成した各種リソースの接続設定をする場合 3.docker-imageを使った、CI/CD:継続的インテグレーションと継続的デリバリーをする場合  ざっくりですがこんなイメージです。 &amp;nbsp; 1はバージョン固定や実行環境を汚さずに使用するメリットがあります。様々な環境でterraformを使用したい場合は直接terraformコマンドをインストールせず、バージョン管理が可能なツール(tfenv)を使用してインストールすルことを勧めます。 &amp;nbsp; 2はTerraformで新規作成したリソースに対し、docker-compose.yml ファイルを使ってアプリケーションの環境を設定します。こちらは公式サイトにて説明がありますので参考にしてください。 http://docs.docker.jp/compose/overview.html
&amp;nbsp; 3は、dockerのImageファイルをdocker hub（リポジトリ）へ保存することで、新規ECSや各種アプリケーション、Webサイトを立ち上げる時、docker hub（リポジトリ）から対象のDocker ImageファイルをPullしそのまま実行することで、どの環境でも継続CI/CDを実現することができます。
本章はTerraformをメインとしてるため、ここにCI/CDや方法は載せませんが、やり方は以下サイトを参照してみてください。（近日中にCI/CD手法を載せる予定です）
Dockerize App and Push to Container Registry: CI/CD Automation on Container Service (1)
Continuous Deployment Automation on Alibaba Cloud: CI/CD Automation on Container Service (2)</description>
    </item>
    
    <item>
      <title>OSSとE-MapReduce</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/007_oss-and-e-mapreduce/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/007_oss-and-e-mapreduce/</guid>
      <description>OSSとE-MapReduce &amp;nbsp; 前述、Hadoop概要、DWHなどBigDataの基本的なことを説明しました。今回はAlibabaCloudで簡単にBigDataができることを記載します。
AlibabaCloudには様々なBigDataプロダクトがあります。BigData絡みだけでこのプロダクトがあります（RDB系、分散DB系、NoSQL系は除外）
これらは順次追って本テクニカルサイトにて手法、ケースを載せます。
   icon プロダクト名 説明 メモ      MaxCompute 大規模データウェアハウジングに対応できるデータ処理プラットフォーム     E-MapReduce E-MapReduce、Hadoopクラスタの展開や運用が可能     RealtimeCompute Apache Flink を最適化したマネージドリアルタイムデータ処理プラットフォーム     DataWorks 大規模データを処理するオンラインIDEサービス     LogService データ収集、クリーニング、分析、視覚化、アラートを実現するマネージドサービス     DataV DataV、データの可視化     QuickBI クラウド上のユーザー向けに調整されたBIサービス     Machine Learning PAI 機械学習と深層学習のデータ処理、モデルトレーニング、サービス展開、予測のためのプラットフォーム     Elasticsearch データ分析、データ検索、機械学習、グラフ、APMなどを実現するマネージドサービス     GraphAnalytics リレーショナルネットワークの分析サービス 中国サイトのみ    DataLakeAnalytics ServerlessでOSS、データベース、NoSQLなどのデータソースでデータを分析するマネージドサービス     OpenSearch 分散検索エンジンプラットフォーム 中国サイトのみ    Hologram PBレベルのデータに対し1秒未満で応答する超高速OLAPマネージドサービス 中国サイトのみ</description>
    </item>
    
    <item>
      <title>Moduleについて</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/07/module/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/07/module/</guid>
      <description>&amp;nbsp; これまでTerraformの書き方を学びました。しかし問題があります。それはvariableによる変数宣言が多すぎると、可読性も下がり、場合によっては何度も同じ内容を書く必要があったりします。それを防ぐために、他のプログラミング言語と同じくモジュール化があります。

1. Moduleとは &amp;nbsp; Terraformにおけるmoduleは各resourceを抽象化するためのものです。以下の例を見てみましょう。モジュール化されてないソースと、モジュール化されてないソースを見てください。
モジュール化されてないソース variable &amp;quot;region&amp;quot; { default = &amp;quot;ap-northeast-1&amp;quot; } variable &amp;quot;solution_name&amp;quot; { default = &amp;quot;Web-Application-for-Terraform&amp;quot; } variable &amp;quot;web_layer_name&amp;quot; { default = &amp;quot;Web&amp;quot; } variable &amp;quot;web_availability_zone&amp;quot; { default = &amp;quot;a&amp;quot; } resource &amp;quot;alicloud_instance&amp;quot; &amp;quot;web&amp;quot; { instance_name = &amp;quot;${var.web_layer_name}&amp;quot; availability_zone = &amp;quot;${var.region}${var.web_availability_zone}&amp;quot; ・・・ ・・・ }  resourceの中に変数のプレースホルダを置き、さらにその変数名を variableで変数宣言し呼び出ししてしまいます。それを抑えるのがmoduleです。
モジュール化されてるソース variable &amp;quot;region&amp;quot; { value = &amp;quot;ap-northeast-1&amp;quot; } variable &amp;quot;solution_name&amp;quot; { value = &amp;quot;Web-Application-for-Terraform&amp;quot; } variable &amp;quot;web_layer_name&amp;quot; { value = &amp;quot;Web&amp;quot; } variable &amp;quot;web_availability_zone&amp;quot; { value = &amp;quot;a&amp;quot; } module { source = &amp;quot;.</description>
    </item>
    
    <item>
      <title>E-MapReduce起動、ETLとOLTP、OLAPをする</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/008_training_etl_and_olap_with_e-mapreduce/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/008_training_etl_and_olap_with_e-mapreduce/</guid>
      <description>E-MapReduceの起動、チューリアトルについて &amp;nbsp; 簡単なチューリアトルとして、E-MapReduceを起動しHiveでOSSにあるCSVファイルをParquetへETLし、HiveでOLTP、ImpalaでOLAPというワークフローをしてみます。
E-MapReduceの起動は非常に簡単です。ゴールとしては以下の通りになります。
Step1: OSSにデータを保存します BigDataを始めるためにはまずデータが必要です。今回はニューヨーク市のタクシーおよびリムジン委員会（NYC TLC）によるタクシーデータ（240GBを超えるCSVファイル）というオープンデータを使って、OSS+E-MapReduceを使用したETL、分析業務の取り込みについて説明します。
https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page ECSインスタンス１台にて、aliyun-cliをインストールします。そのあと、NYTデータをダウンロード、OSSヘアップロードします。
前提として、OSSにBigData専用のディレクトリを作成する必要があります。以下の例では
oss://bigdata-prod-tech/nyc-taxi/yellow_tripdata/csv/ というディレクトリを作成しました。
以下はECS、CentOS 7.6での操作になります。
より詳しいインストール方法はこちらを参考にしてください。
[root@aliyun ~]# [root@aliyun ~]# yum -y install wget 〜 略 〜 [root@aliyun ~]# wget https://aliyuncli.alicdn.com/aliyun-cli-linux-3.0.16-amd64.tgz --2019-06-06 14:18:34-- https://aliyuncli.alicdn.com/aliyun-cli-linux-3.0.16-amd64.tgz Resolving aliyuncli.alicdn.com (aliyuncli.alicdn.com)... 202.47.28.98, 202.47.28.99 Connecting to aliyuncli.alicdn.com (aliyuncli.alicdn.com)|202.47.28.98|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 9159371 (8.7M) [application/x-compressed-tar] Saving to: ‘aliyun-cli-linux-3.0.16-amd64.tgz’ 100%[==============================================================================================================================================================&amp;gt;] 9,159,371 --.-K/s in 0.06s 2019-06-06 14:18:34 (150 MB/s) - ‘aliyun-cli-linux-3.0.16-amd64.tgz’ saved [9159371/9159371] [root@aliyun ~]# tar -xzvf aliyun-cli-linux-3.</description>
    </item>
    
    <item>
      <title>VPCの作成</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/08/vpc/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/08/vpc/</guid>
      <description>&amp;nbsp; ここまではTerraformのインストール方法、コード記載方法、実行方法を説明しました。
ここからはユーザ各自でコード作成、応用ができるよう、AlibabaCloudの基本プロダクトサービスの説明を通じて解説します。
1. VPC &amp;nbsp; VPCは、Alibaba Cloudに設置されたプライベートネットワークです。 VPCはAlibaba Cloudの他のアカウントを含む仮想ネットワークと論理的に分離されています。
&amp;nbsp; VPCはAlibaba Cloud でお客様専用のプライベートネットワークです。 CIDRというIPアドレス範囲の指定で経路、ルートテーブルとネットワークゲートウェイの設定など、VPCを完全に制御できます。VPC環境があることで、ECS、RDS、SLBなど外部インターネットからアクセスしないAlibaba Cloudリソースを使用することができます。
&amp;nbsp; システムをセキュアにするため、パブリックネットワークには必要最小限のリソースのみ配置し、それ以外はプライベートネットワークに置くのがベストプラクティスです。

2. コンポーネント &amp;nbsp; VPCは、CIDRブロック、VRouter、及びVSwitchで構成されます。
・CIDRブロック・・・IPアドレスの空間を指定することで通信経路を出す設定情報。プライベートIPアドレス範囲をCIDR（Classless Inter-Domain Routing）ブロックの形式で指定する必要があります。 ・VRouter・・・VPCのハブ。VPC内の各VSwitchを接続でき、ゲートウェイとしてもVPCを他のネットワークに接続することもできます。 ・VSwitch・・・VPCの基本的なネットワークデバイス、様々なクラウド製品インスタンスに接続するために使用されます。
VPCコンポーネントは以下のような構成図になります。 
また、VPC作成には以下の通り制限事項がありますので、注意が必要です。
   リソース デフォルトの制限 クォータ量の増減     各リージョンでの最大VPC数 10    使用可能なCIDRブロックの範囲 192.168.0.0/16, 172.16.0.0/12, 10.0.0.0/8,及びそのサブセット サポートセンターまでお問い合わせください   VPC 内の VRouter の最大数 1 申請不可   VPC 内の VSwitch の最大数 24 サポートセンターまでお問い合わせください   VPC 内のルータテーブルの最大数 1 申請不可   ルータテーブル内のルートエントリの最大数 48 サポートセンターまでお問い合わせください   VPCで実行できるクラウド製品インスタンスの最大数 15,000 申請不可    参考:VPC使用制限</description>
    </item>
    
    <item>
      <title>既存データからの移植について</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/009_data-collection/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/009_data-collection/</guid>
      <description>OSSをハブとした運用について &amp;nbsp; 前述、OSSとE-MapReduceを説明しました。OSSをハブとして運用することで、コスト削減はもちろん、AlibabaCloudの様々なフルマネージドサービスを中心とした構成が可能となります。
そのため、全ての処理基盤はAlibabaCloudで初め、AlibabaCloudで終わる、という構成も可能です。
同時に、AlibabaCloudのOSSは様々な外部データソースと連携することが可能です。
別の章にてそれぞれのデータソース接続手法を記載します。
2019/07/20 現状確認されてる外部データソースとの接続方法サマリとしては以下の通りになります。
今後このサマリにてApache Beam、Apache Flink、Apache samza、kinesis、Livy、Oracle on Spark、SQL Server on Spark、MongoDB、他の外部データソースも順次追加したいと思います。
運用するときの注意点について データ構造 &amp;nbsp; データを集約した後、どんな分析を行うのか？これを踏まえて、どんな利用方法があるか？をイメージしたテーブル・スキーマ・フィールドタイプ・データ設計をする必要があります。
転送料金 &amp;nbsp; OSSと外部データ（IDCやS3など）でデータやりとりするとき、OSSへInするデータは無料ですが、VPCより先へOutするデータには料金が発生してしまいます。なので、Outするときはデータを圧縮してから移植するなど、工夫が必要です。
ネットワーク &amp;nbsp; データを集約・転送するとき、NW距離ら物理的な要因で処理が遅くなることがあります。そのため、OSSおよび周囲プロダクトサービスとのリージョン・配置はできるだけ近い位置で配置が望ましいです。
ETL &amp;nbsp; ETLは様々な方法がありますが、データ型やhdfsタイプ、仕様上できることできないことを見極めて全体設計が望ましいです。
ex: * HiveやSparkはdate型をサポートしますが、PrestoやImpalaはdate型をサポートしないので読み込み不可 * SparkはORCサポートを打ち切ったため 、代わりの手法はSparkの最新ドキュメントで確認</description>
    </item>
    
    <item>
      <title>ECS、EIPの作成</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/09/ecs/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/09/ecs/</guid>
      <description>AlibabaCloudの基本プロダクトサービスであるECS、EIPの作成方法を解説します。
1. ECS &amp;nbsp; ECSは、Alibaba Cloudによる仮装コンピューティングサービスです。ECS インスタンスは、ECS のコアコンポーネントであり、CPU、メモリ、およびその他の基本的なコンピューティングコンポーネントを含む仮想コンピューティング環境です。ディスク、イメージ、スナップショットなどの他のリソースは、ECS インスタンスと組み合わせてのみ使用できます。 &amp;nbsp; Alibaba CloudのECSはビジネスやWebアプリケーションなど様々なニーズに対応しており、即時に作れることが特徴です。
&amp;nbsp; ECSインスタンス生成リソースは多くのオプション（任意）でパラメータや構成を指定できます。ECSインスタンスはVPCやセキュリティグループとは少し異なり、OSやバージョン選定、起動時データ引き渡しやECS使い捨て利用など様々な利用方法が実現出来るため、ここは抑えておきましょう。

2. ECSインスタンス生成のTerraformについて &amp;nbsp; 本題、ECSインスタンス生成作成に移ります。ECSインスタンス生成するだけの簡単なソースを作ってみます。
resource &amp;quot;alicloud_instance&amp;quot; &amp;quot;ECS_instance&amp;quot; { instance_name = &amp;quot;ECS_instance_for_terraform&amp;quot; host_name = &amp;quot;ECS_instance_for_terraform&amp;quot; instance_type = &amp;quot;ecs.n4.small&amp;quot; image_id = &amp;quot;centos_7_06_64_20G_alibase_20190218.vhd&amp;quot; system_disk_category = &amp;quot;cloud_efficiency&amp;quot; security_groups = [&amp;quot;${alicloud_security_group.sg.id}&amp;quot;] availability_zone = &amp;quot;${var.zone}&amp;quot; vswitch_id = &amp;quot;${alicloud_vswitch.vsw.id}&amp;quot; }  alicloud_instance  instance_name - （オプション）ECSインスタンスの名前。このパラメータを指定しない場合、デフォルト名のECS-Instanceを自動生成します。 host_name - （オプション）ECSのホスト名。 instance_type - （必須）起動するインスタンスの種類。 image_id - （必須）ECSインスタンスに使用するイメージ。ECSインスタンスのイメージは image_idを変更することで置き換えることができます。  image_idの種類や取得方法は後述します。
 system_disk_category - （オプション）ストレージの種類。有効な値はcloud_efficiency 、 cloud_ssd 、およびcloudです。デフォルトはcloud_efficiency。 security_groups - （必須）関連付けるセキュリティグループIDのリスト。 availability_zone - （オプション）インスタンスを起動するゾーン。 vswitch_id - （オプション）接続したいVSwitchのID。 user_data - （オプション）ユーザーデータ。起動直後、実行したいコマンドがあればこちらにて入れます。  このalicloud_instanceリソースを実行することにより、以下の属性情報が出力されます。</description>
    </item>
    
    <item>
      <title>その他</title>
      <link>https://www.sbcloud.co.jp/help/faq/other/</link>
      <pubDate>Fri, 04 Oct 2019 15:30:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/faq/other/</guid>
      <description>目次  NAS  NASの使用可能容量の表示について  RAM  RAMユーザの権限を特定のリージョンに制限する方法について RAMユーザの権限をECS操作のみ可能、購入不可に制限する方法について RAMユーザでSSL Certifcate Serviceを利用時の権限について RAMユーザでコンテナのコンソールを操作させる方法について  Logservice  Logstore の「internal-alert-history」ログについて Logtailの履歴ログのインポートモードについて  ExpressConnect  ExpressConnect同じリージョン内VPC-VPC接続の料金について  CDN  CDNでのAlibaba Cloud の無料証明書申請について CDNオリジンへのリクエストタイムアウト値について CDN + OSS 構成の静的ウェブサイトホスティングについて  Imagesearch  Image SearchのインポートQPS制限について  VPNGAteway  VPNGAtewayのSSL証明書作成仕様について VPNGatewayにて作成可能なSSL証明書数について VPN Gatewayのヘルスチェック設定について SSL-VPNに払い出されるIPアドレスの仕様について  SSL Certifcate  SSL証明書の更新について SSL証明書申請後のドメイン変更について  DataV  DataVでの「コールバックID」の呼び出し範囲について  CEN  CENの帯域幅変更時の通信断発生について  Function Compute  Function Computeの時間トリガーのタイムゾーンについて Function ComputeからRDSのイントラネット接続について  IoT  IoT Platformのデバイス監視機能について  Redis  Redisのパスワードでの接続方法について ApsaraDB for Redisの強制アップグレードについて    NASの使用可能容量の表示について 各NASストレージの容量上限は10.</description>
    </item>
    
    <item>
      <title>LogServiceでOSSへデータを集める方法</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/010_logservice-to-oss/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/010_logservice-to-oss/</guid>
      <description>はじめに &amp;nbsp; 本章はAlibabaCloud LogServiceを使ってOSSへデータを送ります。ゴールとしては以下のような構成図になります。
また、OSSにデータ収集後、E-MapReduceでHDFSへのETL処理がありますが、こちらは「OSSとE-MapReduce編」「ETL編」にて重複するため、割愛させていただきます。
（この章のゴールは外部データソースをOSSへ集約する、のみとなります）
LogServiceとは &amp;nbsp; AlibabaCloudのLogServiceは迅速にログデータを収集、処理、送信、照会/分析することができるプロダクトサービスです。
詳しいことはhelpページにて記載していますので、こちらを参照ください。
https://jp.alibabacloud.com/help/doc-detail/48869.htm
LogServiceでのデータ収集方法 LogServiceでのデータ収集方法は様々な方法がありますが、今回はtwitterのtweetデータを収集、OSSヘ転送する処理を目指します。イメージとしてはECSでTwitterデータを収集、それをLogServiceに転送し、LogServiceによりOSSへParquet形式でデータ転送、という流れになります。
Step1 . LogServiceでプロジェクトの作成、Logstoreを作成します。
こちらにやり方が記載されていますので、説明は割愛します。
https://jp.alibabacloud.com/help/doc-detail/54604.htm
Step2. ECSインスタンスを起動 今回、LogService上で構築することも可能ですが、twitter APIを利用するためにECSでLogService APIと連携して処理します。
下準備として、ECSインスタンスに以下ライブラリのインストールをします。
pip3.6 install -U aliyun-log-python-sdk pip3.6 install twitter 次は以下、Pythonファイルtweet.pyを作成し、実行します。
ssh接続が切れても恒久的に起動し続けたい場合は、nohup python3.6 tweet.py &amp;amp;と実行してください。
# -*- coding: utf-8 -*- from aliyun.log.logitem import LogItem from aliyun.log.logclient import LogClient from aliyun.log.putlogsrequest import PutLogsRequest import time import twitter SCREEN_NAME = &amp;#39;write here&amp;#39; # OAuth こちらはTwitter Developerに申請する必要があります。 # https://developer.twitter.com/content/developer-twitter/ja.html ACCESS_TOKEN_KEY = &amp;#39;&amp;#39; ACCESS_TOKEN_SECRET = &amp;#39;&amp;#39; CONSUMER_KEY = &amp;#39;&amp;#39; CONSUMER_SECRET = &amp;#39;&amp;#39; endpoint = &amp;#39;ap-northeast-1.</description>
    </item>
    
    <item>
      <title>SLBの作成</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/10/slb/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/10/slb/</guid>
      <description>AlibabaCloudの基本プロダクトサービスであるSLBの作成方法を解説します。
1. SLB &amp;nbsp; SLB（Server Load Balancer）はアプリケーションや Web サイトのトラフィックを分散させるサービスです。
&amp;nbsp; SLB は、仮想サービスアドレスを設定することによって、追加の ECS インスタンスを高性能で可用性の高いアプリケーションサービスプールに仮想化し、クライアントからのリクエストを、 転送ルールに従ってサーバープール内のECS インスタンスに分配します。
&amp;nbsp; また、SLB は、追加されたバックエンドサーバーの状態をチェックし、異常状態の ECS インスタンスを自動的に分離します。そうすることで SPOF (単一障害点) 問題を除去し、アプリケ ーションの全体的なサービス性能を向上させます。 それに加え、Alibaba Anti-DDoS と組み合わせることで、SLB は DDoS 攻撃を防御することができます。

2. コンポーネント &amp;nbsp; SLBは以下のコンポーネントが含まれています。
 SLB インスタンス SLB インスタンスは、実行中の負荷分散サービスで、着信トラフィックをバックエンドサーバーに分配します。 負荷分散サービスを使用するには、SLB インスタンスを作成します。インスタンスには少なくとも 1 つのリスナーと 2 つのバックエンドサーバーを設定する必要があります。
 リスナー リスナーはクライアントからのリクエストをチェックし、設定されたルールに基づいてバックエンドサーバーに転送します。 また、バックエンドサーバーのヘルスチェックも実行します。
 バックエンドサーバー バックエンドサーバーは、分散リクエストを処理するために SLB インスタンスに追加された ECS インスタンスです。 分散リクエストを処理する ECSインスタンスは、デフォルトサーバーグループ、VServer グループ、アクティブ/スタンバイサーバーグループのいずれかに追加することができます。
  またServer Load Balancer (SLB) は、 ECS インスタンスの単一障害点 (SPOF)、アクティブゾーンの障害、などを防ぐ役割がありますので、SLBを組み合わせることでサービスの高可用性を実現することができます。</description>
    </item>
    
    <item>
      <title>ECS</title>
      <link>https://www.sbcloud.co.jp/help/faq/ecs/</link>
      <pubDate>Fri, 19 Jul 2019 15:30:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/faq/ecs/</guid>
      <description>目次  一般仕様  アベイラビリティゾーン（AZ）識別文字と実際のロケーションに関するマッピング仕様について 1つのアカウント/リージョン配下のECS購入台数制限について サブスクリプションECSのライフサイクルについて RDSCALとクライアントCALの必要性について ECSのデフォルトタイムゾーンについて スナップショット取得時の性能影響について 購入可能な従量課金インスタンスの上限について 25番ポートの制限について ICP必要性の判断方法について インスタンススペックのアップグレード方法について サブスクリプションインスタンスの削除方法について Linux系OSのSELINUXの設定について Windows日本語バージョンの提供について インスタンス保護機能によりリリースできない事象について 管理コンソールのアクセスにIPレンジの制限方法について  ネットワーク  VPCとVswitchの変更方法について VPCで指定可能なCIDRブロックについて EIPとパブリックIPの違いについて EIPとパブリックIPの帯域幅の変更方法について プライベートIPの変更方法について インバウンドとアウトバウンド帯域幅の制限値について ECSでのIPアドレスの固定方法について VPCのグローバルCIDERルーティング設定について  イメージ  イメージのインポート方法について クラウド移転ツールについて イメージのエクスポート方法について イメージのリージョン間コピー方法について  ディスク  システムディスクとデータディスクの違いについて クラウドディスクの拡張方法について  VNC  VNCで一部記号入力できない事象について VNCパスワードとECSパスワードの違いと再設定方法について VNCのタイムアウト時間について  セキュリティグループ  インバウンドとアウトバウンドのデフォルト動作について 同じセキュリティグループ内のアクセス制限について セキュリティグルールの適用順位について   一般仕様  アベイラビリティゾーン（AZ）識別文字と実際のロケーションに関するマッピング仕様について Alibaba Cloudでは、アベイラビリティゾーン（AZ）識別文字と実際のロケーションのマッピングは、全てのアカウントで共通しています。
AWSにおいては、アカウント毎に個別にマップされます。 仕様が異なるのでご注意ください。
   [⬆ 目次へ]
 1つのアカウント/リージョン配下のECS購入台数制限について 従量課金でのECSインスタンス購入上限は、vCPU数により制限されています。従量課金型ECSインスタンスの購入は各リージョン「50vCPU」までとなっております。なお、サブスクリプション型ECSの場合は、購入上限数を設けておりません。</description>
    </item>
    
    <item>
      <title>OSS</title>
      <link>https://www.sbcloud.co.jp/help/faq/oss/</link>
      <pubDate>Fri, 19 Jul 2019 15:30:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/faq/oss/</guid>
      <description>目次  一般仕様  中国東部1のOSSを利用しなくても課金される事象について 標準、IA、アーカイブの違いについて クロスリージョンレプリケーションの利用制限について パケット間のファイル複製方法について 5G以上のファイルのアップロード方法について 同名ファイルを入れ替え後の即時反映について プライベート/パブリックエンドポイントの違いについて OSSのアクセスログの取得方法について OSSのイメージ/ビデオ処理の利用方法について  製品連携  OSSをディスクとしてマウントする方法について FunctionComputeのトリガーとして利用方法について CDNでOSS静的サイトの公開方法について OSSに静的サイトを設置した場合のICP必要性について OSSにインターネット経由で接続する際のFQDNについて  権限  RAMユーザー対象にバケットアクセス権限の制御方法について OSS公開してもディレクトリにアクセスできない事象について RAMユーザー利用時のBucketList権限の必要性について   一般仕様  中国東部1のOSSを利用しなくても課金される事象について OSSコンソールでのパケット操作は実質上にAPIで実行されています。
GetBucketなどのようなパケットを特定しないに操作以外、共通な属性を取得するようなリクエストを実行された場合、デフォルトで中国東部１リージョンのエンドポイントが利用される仕様となります。
コンソールからのAPIリクエストにより発生した料金は中国東部1のパケットに記録されますので、中国東部1のOSSを利用しなくても課金される事象の原因となります。
   [⬆ 目次へ]
 標準、IA、アーカイブの違いについて 標準ストレージと比較する場合、低頻度アクセスストレージに保存したファイルを30日以内、アーカイブストレージは60日以内に削除した場合、料金がかかります。 そして、アーカイブストレージからファイルを取り出す場合、解凍時間が必要となります。
標準ストレージ
高パフォーマンス、高信頼性、高可用性を実現する OSS インスタンス
特徴：高スループット、ホットファイル、頻繁なアクセスを特徴とするサービスシナリオに適用可能
信頼性: 99.999999999%
最小保存期間：なし
適用シナリオ: モバイルアプリケーション、大規模な Web サイト、画像共有、アクセス頻度の高いオーディオとビデオ
低頻度アクセスストレージ
比較的低いストレージコストとリアルタイムのアクセスを特徴とする OSS インスタンス
特徴： リアルタイムの低頻度データアクセスをサポートするサービスシナリオに適用可能
信頼性: 99.999999999%
最小保存期間：30 日
適用シナリオ： アプリケーションデータとエンタープライズデータのバックアップ、モニタリングデータ、オンラインストレージアプリケーション
アーカイブストレージ</description>
    </item>
    
    <item>
      <title>RDS</title>
      <link>https://www.sbcloud.co.jp/help/faq/rds/</link>
      <pubDate>Fri, 19 Jul 2019 15:30:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/faq/rds/</guid>
      <description>目次  一般仕様  RDSのトラフィック料金について sysadminの権限提供について カスタマイズ可能なパラメーターについて RDSのストレージ容量の拡張方法について ホワイトリストの設定方法について インターネットアドレスとイントラネットアドレスの違いについて VPCとVswitchの変更方法について Oracleライセンスの持ち込みについて  バックアップ  バックアップ取得時の性能影響について RDSバックアップの保存先について リカバリ時に指定可能な時刻について RDSリリース後のバックアップ提供について  マルチゾーン  マルチゾーンの確認方法について マルチゾーンの切り替え方法について レプリカのマルチゾーン対応について  暗号化  保存データの暗号化方法について SSLを利用するデータ転送方法について   一般仕様  RDSのトラフィック料金について RDS現在トラフィック（インバウンド、アウトバウンド含む）料金は無料です。
  [⬆ 目次へ]
 sysadminの権限提供について インスタンスの安定性とセキュリティを保証するために、RDS for SQL Server では、sysadmin 権限を提供しておりません。
RDSの制限詳細は下記のドキュメントをご参照ください。
https://jp.alibabacloud.com/help/doc-detail/26141.htm
   [⬆ 目次へ]
 カスタマイズ可能なパラメーターについて RDSはマネジメントサービスのため、カスタマイズ可能なパラメーターはRDSコンソールのパラメーターの設定ページに表示されているパラメーターのみとなります。
  [⬆ 目次へ]
 RDSのストレージ容量の拡張方法について RDSのストレージ容量は下記メニューから拡張することができます。
コンソール &amp;gt; RDS &amp;gt; インスタンスの「詳細」&amp;gt; 設定を変更する &amp;gt; 容量</description>
    </item>
    
    <item>
      <title>SLB</title>
      <link>https://www.sbcloud.co.jp/help/faq/slb/</link>
      <pubDate>Fri, 19 Jul 2019 15:30:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/faq/slb/</guid>
      <description>目次  一般仕様  レイヤー4とレイヤー7のSLBの違いについて SLBのアクセスログについて SLBのスペック変更方法と業務影響について VServerグループとマスタースレーブグループの違いについて サードパーティ証明書のアップロード方法について SLB関連の各APIのスロットリング上限について SLBの接続要求のタイムアウト時間について SLBスペック変更に伴うサービス切断について  ネットワーク  パブリックSLBとプライベートSLBの違いについて パブリックSLBとバックエンドECS間の通信仕様について パブリックIPとプライベートIP付きSLBの作成方法について ホワイトリストとブラックリストについて SLBのインバウンド/アウトバウンド帯域幅について 証明書をSLB側とECS側に設置の違いについて TCP over SSLの対応について SLBのTLSバージョン選択機能について  負荷分散  ラウンドロビン利用時に分散されない事象について バックエンドECSの重み設定について APIでVserverグループ追加時の引数書き方について SLBの相互認証について SLBを利用したsorryサーバーの実装方法について  ヘルスチェック  SLBのヘルスチェック頻度の仕様について SLBのヘルスチェック用CIDRブロックについて   一般仕様  レイヤー4とレイヤー7のSLBの違いについて SLBはレイヤ4 (TCP、UDP)およびレイヤ7(HTTP、HTTPS)を提供しています。
レイヤ 4 SLB は、ロードバランシングを実現するために keepalived のオープンソースソフトウェアの Linux 仮想サーバー（ LVS ）を使用し、クラウドコンピューティングの要件に応じて、いくつかのカスタマイズを行っています。
レイヤ 7 SLB は、ロードバランシングを実現するために Tengine を使用しています。 Tengine、Nginx に基づいて Web サーバープロジェクトは、多量トラフィックのウェブサイトに対応する機能を追加しています。
  [⬆ 目次へ]</description>
    </item>
    
    <item>
      <title>アカウント</title>
      <link>https://www.sbcloud.co.jp/help/faq/account/</link>
      <pubDate>Fri, 19 Jul 2019 15:30:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/faq/account/</guid>
      <description>目次  アカウント  TOTP認証利用できなくなった時の対応方法について メールアドレスの変更方法について クレジットカードの変更方法について アカウント登録氏名（社名）の変更方法について コンソール自動ログアウトの仕様について   アカウント  TOTP認証利用できなくなった時の対応方法について バインドしている携帯電話を紛失したり、TOTP認証アプリケーションを削除する等、何らかの理由で認証が行えなくなった場合、バインド解除を申請することができます。
申請方法は下記のドキュメントをご参照ください。
https://jp.alibabacloud.com/help/faq-detail/54827.html
   [⬆ 目次へ]
 メールアドレスの変更方法について ログインに使用するメールアドレス（ログインアカウント）は変更することができます。
変更方法は下記のドキュメントをご参照ください。
https://jp.alibabacloud.com/help/doc-detail/52915.html
   [⬆ 目次へ]
 クレジットカードの変更方法について アカウントには最低1枚のクレジットカードを登録する必要があります。
このため、クレジットカードの変更は、以下の手順で操作します。
①新しいカードを追加
②既存カードを削除
変更方法は下記のドキュメントをご参照ください。
https://jp.alibabacloud.com/help/doc-detail/50107.html
   [⬆ 目次へ]
 アカウント登録氏名（社名）の変更方法について アカウントにクレジットカードを追加・有効化完了後は、コンソールから登録名（個人：姓名、法人：会社名）を変更することができません。
変更が必要な場合、チケット起票してサポートセンターに連絡する必要があります。
なお、法人アカウントの「担当者名（連絡先情報の姓名）」はコンソールにログイン後、下記リンクにて変更できます。（チケットを起票する必要はありません。） https://myaccount.aliyun.com/account/complete-profile#/content
   [⬆ 目次へ]
 コンソール自動ログアウトの仕様について 操作の有無に関係なく、コンソールにログインしてから3時間経過すると、タイムアウトでセッションが切れ、自動的にログアウトされます。
  [⬆ 目次へ]</description>
    </item>
    
    <item>
      <title>AWS S3からOSSへ</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/011_aws-s3-to-oss/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/011_aws-s3-to-oss/</guid>
      <description>はじめに &amp;nbsp; 本ページはAWS S3からAlibabaCloud OSSへデータを移植する方法をまとめます。 本ページは具体的な手法より、どんな手法があるかをメインに記載します。
Data Migration Serviceを使った移植方法 ※Data Migration Serviceは国際サイト専用のサービスです Data Migration Serviceを使った移植方法
https://www.alibabacloud.com/blog/migrating-from-aws-s3-to-alibaba-cloud-oss-using-data-migration-service_594382
VPN経由でS3からOSSへ移植 VPN経由でS3からOSSへのマイグレーション
https://www.sbcloud.co.jp/entry/2018/12/03/s3-vpn-oss/
OSSImportツール（スタンドアロン）を使った移植 OssImportのアーキテクチャと構成、ダウンロードページ
https://jp.alibabacloud.com/help/doc-detail/56990.html
AWS S3からAlibaba Cloud OSSへのマイグレーション手順
https://www.sbcloud.co.jp/file/98012380859496046
AlibabaCloudへのマイグレーション -ストレージ編-
https://www.sbcloud.co.jp/entry/2018/10/31/migration_oss/
OSSImportツール（分散モード）を使った移植（分散版） OssImportのアーキテクチャと構成、ダウンロードページ
https://jp.alibabacloud.com/help/doc-detail/56990.html
OssImport を使用したデータの移行
https://jp.alibabacloud.com/help/doc-detail/59922.htm
分散デプロイについて
https://jp.alibabacloud.com/help/doc-detail/57057.htm
emr-toolを使って移植する方法 AWS EMRにてAlibabaCloudのemr-toolをセットアップ、hdfsデータの保存先(接続先パス、エンドポイント）をAlibabaCloud OSSへ指定し移植します。
HDFS の OSS へのバックアップ
https://jp.alibabacloud.com/help/doc-detail/63822.html
Spark分散を使った移植方法 AWS EMRにてSpark分散処理を実施、保存先(接続先パス、エンドポイント）をAlibabaCloud OSSへ指定するだけです。
最後に AWS S3からの移植方法は様々な方法があります。ここには書いていない方法もありますので、検証次第、追記したいと思います。
またS3からOSSへ移植するとき、注意したいことが以下の三点です。
 S3とOSSとのNW距離（リージョンが近ければGood） NW帯域（データが多いのであれば分散で移植した方がベター） S3からの転送料金（データが多いほどOut料金が高くなります）  これを踏まえてS3からOSSへ気軽なデータ移植（Import）ができれば幸いです。</description>
    </item>
    
    <item>
      <title>AutoScalingの作成</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/11/autoscaling/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/11/autoscaling/</guid>
      <description>AlibabaCloudの基本プロダクトサービスであるAutoscalingの作成方法を解説します。
1. AutoScaling &amp;nbsp; Auto Scaling はECSリソースの容量を自動的にスケールイン/スケールアウト調整してくれます。 ※ESSとは、SDK名やパッケージ名で用いられるAuto Scalingの略称です。（Elastic Scaling Service）

2. コンポーネント &amp;nbsp; VPCは、CIDRブロック、VRouter、及びVSwitchで構成されます。
・スケールアウト ECSリソースが増加した際、自動的にECSインスタンスが作成されるので、アクセス遅延や過度のリソース負荷を回避できます。 ・スケールイン ビジネスニーズに伴い、基盤となるECAリソースが低下した場合、自動的にECSインスタンスが削除され、リソースの無駄を省いてくれます。 ・柔軟なリカバリ 異常なECSインスタンスを検知し、自動的にリリースされ、代わりに新規ECSインスタンスが作成されます。 3. AutoScalingのTerraformについて &amp;nbsp; 本題、AutoScaling作成に移ります。以下の構成図通り、簡単なソースを作ってみます。
resource &amp;quot;alicloud_ess_scaling_group&amp;quot; &amp;quot;scaling&amp;quot; { min_size = 2 max_size = 10 scaling_group_name = &amp;quot;tf-scaling&amp;quot; vswitch_ids=[&amp;quot;${alicloud_vswitch.vsw. *.id}&amp;quot;] loadbalancer_ids = [&amp;quot;${alicloud_slb.slb. *.id}&amp;quot;] removal_policies = [&amp;quot;OldestInstance&amp;quot;, &amp;quot;NewestInstance&amp;quot;] depends_on = [&amp;quot;alicloud_slb_listener.http&amp;quot;] } resource &amp;quot;alicloud_ess_scaling_configuration&amp;quot; &amp;quot;config&amp;quot; { scaling_group_id = &amp;quot;${alicloud_ess_scaling_group.scaling.id}&amp;quot; image_id = &amp;quot;ubuntu_140405_64_40G_cloudinit_20161115.vhd&amp;quot; instance_type = &amp;quot;ecs.n2.small&amp;quot; security_group_id = &amp;quot;${alicloud_security_group.default.id}&amp;quot; active=true enable=true user_data = &amp;quot;#!</description>
    </item>
    
    <item>
      <title>IDCからOSSへ</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/012_idc-to-oss/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/012_idc-to-oss/</guid>
      <description>はじめに &amp;nbsp; 本ページはIDCからAlibabaCloud OSSへデータを移植する方法をまとめます。 本ページは具体的な手法より、どんな手法があるかをメインに記載します。
ExpressConnectを使用した方法 物理接続を介したオンプレミス IDC からの VPC への接続
https://jp.alibabacloud.com/help/doc-detail/44844.htm
Hybrid Cloud Storage Arrayを使用した方法 ※ Hybrid Cloud Storage Arrayは国際サイトのみ提供となります。
Hybrid Cloud Storage Array
https://www.alibabacloud.com/product/storage-array
オンプレミスとのクロスレプリケーションによるバックアップ方法
https://medium.com/@Alibaba_Cloud/hybrid-cloud-storage-cross-cloud-replication-5b5a3dee8ff1
OSSImport（スタンドアロン）を使用した方法 OssImportのアーキテクチャと構成、ダウンロードページ
https://jp.alibabacloud.com/help/doc-detail/56990.html
OssImport を使用したデータの移行
https://jp.alibabacloud.com/help/doc-detail/59922.html
AlibabaCloudへのマイグレーション -ストレージ編-
https://www.sbcloud.co.jp/entry/2018/10/31/migration_oss/
emr-toolを使って移植する方法 IDCオンプレミスにてAlibabaCloudのemr-toolをセットアップ、hdfsデータの保存先(接続先パス、エンドポイント）をAlibabaCloud OSSへ指定して移植します。
HDFS の OSS へのバックアップ
https://jp.alibabacloud.com/help/doc-detail/63822.html
Spark分散を使った移植方法 IDCオンプレミス側にてSpark分散処理を実施、そのとき保存先（接続先）パスをAlibabaCloud OSSへ指定するだけです。
最後に IDCオンプレミスからの移植方法はAWS S3と同様、様々な方法があります。ここには書いていない方法もありますので、検証次第、追記したいと思います。
またIDCからOSSへ移植するとき、注意したいことが以下の三点です。
 IDCオンプレミスとOSSとのNW距離（リージョンが近ければGood） NW帯域（データが多いのであれば分散で移植した方がベター）  これを踏まえてIDCオンプレミスからOSSへ気軽なデータ移植（Import）ができれば幸いです。</description>
    </item>
    
    <item>
      <title>OSSの作成</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/12/oss/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/12/oss/</guid>
      <description>AlibabaCloudの基本プロダクトサービスであるObject Storage Serviceの作成方法を解説します。
1. OSS &amp;nbsp; Object Storage Service （OSS）は、クラウド内の任意の量のデータの保存、バックアップ、およびアーカイブを可能にするストレージサービスです。

2. コンポーネント &amp;nbsp; OSSはTerraform モジュールを使用して、バケットとオブジェクトを管理できます。 例として、
 バケット管理機能 バケットの作成 バケットの ACL を設定 バケットに CORS (Cross-Origin Resource Sharing) を設定 バケットのログ記録を設定 バケットの静的 Web サイトホスティングを設定 バケットのリファラを設定 バケットのライフサイクルルールを設定 オブジェクト管理機能 オブジェクトをアップロード オブジェクトのサーバー側の暗号化を設定 オブジェクトに ACL を設定 オブジェクトメタを設定  などが上げられます。

3. OSSのTerraformについて &amp;nbsp; 本題、OSS作成に移ります。プライベートバケットを作成するという簡単なソースを作ってみます。
resource &amp;quot;alicloud_oss_bucket&amp;quot; &amp;quot;bucket-acl&amp;quot;{ bucket = &amp;quot;bucket-170309-acl&amp;quot; acl = &amp;quot;private&amp;quot; }  alicloud_oss_bucket  bucket - （オプション）バケットの名前。 acl - （任意）ACL。デフォルトは &amp;ldquo;private&amp;rdquo;。  他、OSSに関してはalicloud_oss_bucketだけで色々なリソース作成が可能です。例えば以下の例があります。</description>
    </item>
    
    <item>
      <title>ApacheSpark（Batch）からOSSへ</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/013_apache-spark-to-oss/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/013_apache-spark-to-oss/</guid>
      <description>はじめに &amp;nbsp; 本章はApache Spark（Batch）を使ってAlibabaCloud OSSへデータを送ります。ゴールとしては以下のような構成図になります。
ApacheSparkでやる理由 &amp;nbsp; 別途、Apache Sparkとは何かを説明しました。これを使ってやる理由について説明します。 SparkはTB、PB、EB級の大量データを扱うことができます。マシン1台で処理できないデータでも、E-MapReduceとSparkを使えば分散してデータを取得・処理することができます。そのため、処理に時間がかかるものはSparkを積極的に活用することで、ビジネス上メリットを得ることができます。
&amp;nbsp; Sparkの便利なことはIN/OUTデータソースが様々な形式へサポートしています。そのため、例えばcsvファイルをHDFS Parquetとして保存したり、MySQLやOracleのデータをHDFSとして保存、逆にOracleのデータをMySQLへ移植、HDFS_Parquetをcsvファイルへ保存することも可能です。
   データソース text json csv parquet orc jdbc     IN ◯ ◯ ◯ ◯ ◯ ◯   OUT ◯ ◯ ◯ ◯ ◯ ◯    
&amp;nbsp; それでは実際にSpark処理をやってみます。今回はE-MapReduceを使って実装します。 ※ECSでも実現可能。その場合、スタンドアロン（単体）での処理になります。
Spark-Shell（対話型）で試してみる Spark Batch処理をする前に、処理の流れとしてSparl-Shellを使って説明します。以下サンプルを入れていますので、流れをみていただければと思います。
環境について    Clustor instance Type 台数     Hadoop EMR-3.22.0 MASTER ecs.sn2.large 1    CORE ecs.</description>
    </item>
    
    <item>
      <title>RDSの作成</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/13/rds/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/13/rds/</guid>
      <description>AlibabaCloudの基本プロダクトサービスであるRelation Database Serviceの作成方法を解説します。
1. RDS &amp;nbsp; Relation Database Service （RDS）は、ApsaraDB for RDS 、クラウド内の独立したデータベースサービスです。
2. コンポーネント &amp;nbsp; ApsaraDB for RDSシリーズとしてMySQL、SQL Server、PostgreSQL、PPASがあります。
・ApsaraDB for MySQL・・・MySQL。現状5.5、5.6、5.7をサポートしています。
・ApsaraDB for SQL Server・・・SQL Server。2008 R2 EE、2012 のWeb/Standard/EE、2016 のWeb/Standard/EEをサポートしています。
・ApsaraDB for PostgreSQL・・・PostgreSQL。9.4をサポートしています。
・ApsaraDB for PPAS・・・Postgres Plus Advanced Server （ PPAS ）、Oracle Database互換性機能があります。現在バージョン 9.3 をサポートしています。
3. RDSのTerraformについて &amp;nbsp; 本題、RDS作成に移ります。ApsaraDB for MySQLというインスタンスを作成し、databaseをセット、アカウントを作成する内容です。
resource &amp;quot;alicloud_db_instance&amp;quot; &amp;quot;default&amp;quot; { engine = &amp;quot;MySQL&amp;quot; engine_version = &amp;quot;5.6&amp;quot; instance_type = &amp;quot;rds.mysql.t1.small&amp;quot; instance_storage = 5 vswitch_id = &amp;quot;${var.</description>
    </item>
    
    <item>
      <title>ApacheSpark（Streaming）からOSSへ</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/014_apache-spark-streaming-to-oss/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/014_apache-spark-streaming-to-oss/</guid>
      <description>はじめに &amp;nbsp; 本章はApache Spark（Streaming）を使ってAlibabaCloud OSSへデータを送ります。ゴールとしては以下のような構成図になります。 また、OSSにデータ収集後、E-MapReduceでHDFSへのETL処理がありますが、こちらは「OSSとE-MapReduce編」「ETL編」にて重複するため、割愛させていただきます。 （この章のゴールは外部データソースをOSSへ集約する、のみとなります）
Apache Spark Streaming とは &amp;nbsp; Apache Spark Streamingは大規模ストリーム処理フレームワークです。 Spark APIを拡張し、データサイエンティスト、エンジニアがKafka、Flume、Ignite、などのさまざまなソースからのリアルタイムデータを処理できるようにします。この処理されたデータは、OSS、MySQLなどのデータベース、ElasticSearchなどライブダッシュボードに出力できます。また、Spark Streamingは、MLlibやSpark SQLなど他のSparkコンポーネントとシームレスに統合できるので、加工処理、抽出、など様々な応用ができます。 さてPythonを使ってSpark Streamingのテストをしてみます。今回、手頃にいいデータがなかったので、TCPソースからストリームデータを作成し、その結果をOSSへ書き込むという処理を目指します。
SocketTextStreamメソッドはTCPソース(hostname:port)からinputデータを生成、データはTCPソケットを使用して受け取とられ、UTF-8でエンコードし、¥nをデリミタとした行単位でバイトで受け取ります。 今回はAlibabaCloud E-MapReduceで実施するため、TCPソース(hostname:port)はE-MapReduceのHostname、使われてないPort 9999を使用します。
環境について    Clustor instance Type 台数     Hadoop EMR-3.22.0 MASTER ecs.sn2.large 1    CORE ecs.sn2.large 2    E-MapReduceのHostは以下コマンドで取得します。
[root@emr-header-1 ~]# [root@emr-header-1 ~]# hostname emr-header-1.cluster-44076 [root@emr-header-1 ~]#  続いて、Pythonソースにて、コードを記載します。
# -*- coding:utf-8 -*- import sys from pyspark.</description>
    </item>
    
    <item>
      <title>RAMの作成</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/14/ram/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/14/ram/</guid>
      <description>AlibabaCloudの基本プロダクトサービスであるResource Access Managementの作成方法を解説します。
1. RAM権限管理 &amp;nbsp; AlibabaCloudはどのサービスを利用・操作するにしろ権限が必要です。 Terraformで作成したリソースサービスにも他ユーザが操作できるように権限アタッチが必要になります。 &amp;nbsp; 本章では、AlibabaCloudサービスに対する権限付与の方法を学びます。

2. Alibaba CloudのRAMについて &amp;nbsp; RAM（Resource Access Management）はユーザーID の管理とアクセス制御、権限管理のためのサービスです。RAMを使用することで、ユーザーアカウント (従業員、システム、アプリケーションなど) を作成および管理し、Alibaba Cloud アカウントのリソースに対してそのユーザーアカウントが所有する操作権限を制御できます。Terraformによるリソースを実行するときはRAMで実行権限が必須です。

3. RAMロールとRAMユーザーの違い  RAMロールは仮想ID であり、固定のIDは持っていますが、ID認証情報アクセスキーを持ちません。 RAMユーザは、固定のIDとID認証アクセスキーを持つ実際のIDであり、一般的には、特定のユーザーまたはアプリケーションに対応します。  graph LR; A(&amp;#34;ポリシーサービスに&amp;lt;br&amp;gt;対する権限&amp;#34;)-.-&amp;gt;B(&amp;#34;RAMポリシーを&amp;lt;br&amp;gt;ロールにアタッチ&amp;#34;) A(&amp;#34;ポリシーサービスに&amp;lt;br&amp;gt;対する権限&amp;#34;)-.-&amp;gt;C(&amp;#34;RAMポリシーを&amp;lt;br&amp;gt;ユーザにアタッチ&amp;#34;) B(&amp;#34;RAMポリシーを&amp;lt;br&amp;gt;ロールにアタッチ&amp;#34;)-.-&amp;gt;D(&amp;#34;ロール(役割)&amp;#34;) C(&amp;#34;RAMポリシーを&amp;lt;br&amp;gt;ユーザにアタッチ&amp;#34;)-.-&amp;gt;E(&amp;#34;ユーザ(人)&amp;#34;) D(&amp;#34;ロール(役割)&amp;#34;)-.-&amp;gt;F(&amp;#34;ロール(役割)を&amp;lt;br&amp;gt;エンティティ(ECSインスタンスなど）にアタッチ&amp;#34;) A(&amp;#34;ポリシーサービスに&amp;lt;br&amp;gt;対する権限&amp;#34;)-.-&amp;gt;G(&amp;#34;RAMポリシーを&amp;lt;br&amp;gt;グループにアタッチ&amp;#34;) G(&amp;#34;RAMポリシーを&amp;lt;br&amp;gt;グループにアタッチ&amp;#34;)-.-&amp;gt;H(&amp;#34;グループ（ユーザの集まり）&amp;#34;) &amp;nbsp; RAMロールは権限が付与された実際のユーザーが引き受ける必要があります。ロールを引き受けると実際のユーザーはこのRAMロールの一時セキュリティトークンを受け取ります。これにより、この一時セキュリティトークンを使用して、ロールに許可されているリソースにアクセスできます。
&amp;nbsp; 普段の利用時はRAMユーザで管理・運用していくのがベストプラクティスですが、Terraform利用時は基本的にAdministratorAccessが必要となります。
4. ポリシー &amp;nbsp; 権限はポリシーで定義します。ポリシーでは「実行可能なアクション」や「操作可能なリソース」を指定でき、柔軟に権限が設定できます。
5. ポリシードキュメント &amp;nbsp; ポリシードキュメントはJSON形式で管理しており、以下のようにまとめます。 ▼JSON 形式のポリシードキュメント
{ &amp;quot;Statement&amp;quot;: [ { &amp;quot;Action&amp;quot;: &amp;quot;*&amp;quot;, &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;, &amp;quot;Resource&amp;quot;: &amp;quot;*&amp;quot; } ], &amp;quot;Version&amp;quot;: &amp;quot;1&amp;quot; }  ポリシードキュメントでは、次のような要素を記述します。 * Effect - 許可する場合はAllow、許可しない場合はDeny * Resource - AlibabaCloudの操作可能なリソース・許可されたオブジェクトはなにかを指定します。たとえば ”ユーザAがリソースSampleBucketに対してGetBucket操作を実行できる” という権限付与ポリシーの場合、ResourceはSampleBucket です。 * Action - AlibabaCloudの各種サービスでどんな操作が実行できるか。サービスを個別指定することも可能。たとえば ”ユーザAがリソースSampleBucketに対してGetBucket操作を実行できる” という権限付与ポリシーの場合、ActionはGetBucket です。 * Condition - 権限付与が有効になる条件です。たとえば、”ユーザAが2018年12月31日より前にリソース SampleBucketに対してGetBucket操作を実行できる” という権限付与ポリシーの場合、Conditionは 2018年12月31日より前 です。</description>
    </item>
    
    <item>
      <title>Kubernetesの作成</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/terraform/15/kubernetes/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/terraform/15/kubernetes/</guid>
      <description>AlibabaCloudの基本プロダクトサービスであるResource Access Managementの作成方法を解説します。
1. Kubernetes &amp;nbsp; Kubernetesは自動デプロイ、スケーリング、アプリ・コンテナの運用自動化のために設計されたオープンソースのプラットフォームです。Kubernetesによって、以下のことが要求に迅速かつ効率良く対応ができます。
 アプリを迅速に予定通りにデプロイする (コンテナをサーバー群へ展開する) 稼働中にアプリをスケールする（稼働中にコンテナ数を変更する） 新機能をシームレスに提供開始する (稼働中にロールアウトする) ハードウェアの利用率を要求に制限する (コンテナで共存させて稼働率を高くする）  &amp;nbsp; Kubernetesのゴールは、下記の様なアプリの運用負担を軽減するためのエコシステムのコンポーネントとツールを整備することです。
 可搬性: パブリック・クラウド、プライベート・クラウド、ハイブリッド・クラウド、マルチ・クラウド 拡張可能: モジュール化、追加可能、接続可能、構成可能 自動修復: 自動配置、自動再起動、自動複製、自動スケーリング  &amp;nbsp; 2014年にプロジェクトが開始され、運用経験を基に、本番のワークロードを大規模に実行し、コミュニティのベストプラクティスのアイデアやプラクティスと組み合わせています。 Kubernetesの事例は https://kubernetes.io/case-studies/ にあります。
&amp;nbsp; またAlibabaのKubernetesサービスは非常に便利な上、Container Clustor、kubernetes managed、Container Registryと各方面へ進化段階なので、随時チェックするといいでしょう。

2. コンポーネント &amp;nbsp; Container Service for Kubernetes はネイティブの Kubernetes をベースに構成、拡張されています。 このサービスは、クラスターの作成および拡張を容易に行うことができ、Alibaba Cloud の機能である、仮想化、ストレージ、ネットワーク、セキュリティ、およびKubernetes コンテナー化したアプリケーションの高品質な実行環境を統合することができます。
3. KubernetesのTerraformについて &amp;nbsp; 本題、Kubernetesクラスタ作成に移ります。AZシングルゾーンのKubernetesクラスタを生成するだけの簡単なソースを作ってみます。
resource &amp;quot;alicloud_cs_kubernetes&amp;quot; &amp;quot;main&amp;quot; { name_prefix = &amp;quot;my-first-k8s&amp;quot; availability_zone = &amp;quot;${data.alicloud_zones.default.zones.0.id}&amp;quot; new_nat_gateway = true master_instance_types = [&amp;quot;ecs.</description>
    </item>
    
    <item>
      <title>Apache FlumeからOSSへ</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/016_apache-flume-to-oss/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/016_apache-flume-to-oss/</guid>
      <description>はじめに &amp;nbsp; 本章はApache Flumeを使ってOSSへデータを送ります。ゴールとしては以下のような構成図になります。 また、OSSにデータ収集後、E-MapReduceでHDFSへのETL処理がありますが、こちらは「OSSとE-MapReduce編」「ETL編」にて重複するため、割愛させていただきます。 （この章のゴールは外部データソースをOSSへ集約する、のみとなります）
Apache Flumeとは &amp;nbsp; Apache Flumeは堅牢性が高く、耐障害性のある分散データ取り込みツールです。さまざまなデータソース（Webサーバーなど）からHadoop分散ファイルシステム（HDFS）、HDFS上のHBaseやkuduなどの分散データベース、またはElasticsearchなど大量のログファイルをストリーミングすることができます。Flumeはログデータのストリーミングに加えて、Twitter、Facebook、Kafka BrokersなどのWebソースから生成されたEventデータをストリーミングすることもできます。 Apache Flumeでより詳しいことは公式サイトを参照ください。 https://flume.apache.org/ Flumeの概要 &amp;nbsp; Apache Flumeはクラスターへのデータの取り込み（ingres）に特化しています。特に数台または数千台のマシンに蓄積されているログファイルを収集、集約、クラスター内の単一のエントリポイントにストリーミングできます。Flumeのコンポーネントと概念についてを以下にて説明します。
 Event：Flumeによって転送されるデータの基本ペイロード。Flumeが発信元から最終目的地まで転送できるデータの単位を表します。オプションのヘッダーはインターセプターを介してチェーン化され、通常はEventの検査と変更に使用されます。 Client：Eventの起点で動作し、それらをFlumeAgentに配信するインターフェース実装。Clientは通常、データを消費しているアプリケーションのプロセス空間で動作します。 Agent： Flumeのデータパスのコア要素。ホストは、Source、Channel、Sinkなどのコンポーネントを使用し、Eventを受信、保存、およびネクストホップの宛先に転送する機能を備えています。 Source：Client経由で配信されるEventを消費します。SourceがEventを受信すると、それを1つ以上のChannelに渡します。 Channel：Eventの一時ストア。SourceとSinkの間のリンク部分です。Channelは、フローの耐久性を確保する上で重要な役割を果たします。 Sink：ChannelからEventを削除し、フロー内の次のAgentまたはEventの最終宛先に送信します。Eventを最終宛先に送信するSinkは、ターミナルシンクとも呼ばれます。  EventはClientからSourceへ流れます。Sourceは、Eventを1つ以上のChannel書き込みます。Channelは、処理中のEventデータ保持領域であり、永続的（ファイルバックアップ）または非永続的（メモリバックアップ）に構成できます。Eventデータは、Sinkがそれを処理し、データを最終宛先に送信できるようになるまで、Channelで待機します。
以下は、HDFS（OSS）ターミナルシンクで構成されたシンプルなFlumeエージェントを示しています。
参考：Apache Flumeガイドライン http://flume.apache.org/FlumeUserGuide.html Flumeを使ってデータを取り込む &amp;nbsp; 今回はTwitter情報をFlumeで収集しHDFSフォルダをOSSとして格納するという流れを目指します。
環境について    Clustor instance Type 台数     Hadoop EMR-3.22.0 MASTER ecs.sn2.large 1    CORE ecs.sn2.large 2    
Step1. Twitter APIを発行 こちらはTwitter Developerに申請する必要があります。 https://developer.twitter.com/content/developer-twitter/ja.html Step2.</description>
    </item>
    
    <item>
      <title>SSH踏み台サーバの作成</title>
      <link>https://www.sbcloud.co.jp/help/scenario/terraform/bastion-server/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/scenario/terraform/bastion-server/</guid>
      <description>ssh踏み台サーバ &amp;nbsp; クラウド上にてEC2やOSS、RDSなどにて個人情報や外部流出したくないしたくない危険なファイルがある場合、インターネットら外部からメインサーバが見える状態は極力避けたいです。それを防ぐために様々な手段がありますが、費用対効果の高いネットワーク構造として踏み台サーバを作る方法があります。踏み台サーバーとは、インターネットに直接繋がないサーバーをSSHで接続するために経由される、セキュリティ層の役割を満たすことができるサーバーのことです。踏み台サーバを使うことで、以下のメリットがあります。
 実行用など本番に使う各サーバに直接アクセスできないため、外部からの侵入リスクを軽減できる。 PublicIPを実行用など本番に使う各サーバに割る必要がないため、運用における負荷を軽減できる。 踏み台サーバから実行用など本番に使う各サーバへのログを残せるため、不正操作を防げれる。  

構成としては以下の図通りになります。

&amp;nbsp; Terraformで踏み台サーバ、本番サーバを作ってみます。ゴールの構成図は以下の通りです。
それぞれのパラメータは以下の通りです。
ネットワーク構成:
   リソース リソース名 パラメータ 必須 設定値 内容     alicloud_vpc vpc name 任意 ${var.project_name}-vpc VPC の名称。この例の場合、Bastion-Server-for-Terraform-vpc として表示されます。    vpc cidr_block 必須 192.168.1.0/24 VPC の CIDR ブロック    vpc description 任意 Enable Bastion-Server vpc VPC の説明。   alicloud_vswitch vsw name 任意 ${var.project_name}-vswitch vswitch の名称。この例の場合、Bastion-Server-for-Terraform-vswitch として表示されます。    vsw vpc_id 必須 ${alicloud_vpc.</description>
    </item>
    
    <item>
      <title>FluentdからOSSへ</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/017_fluentd-to-oss/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/017_fluentd-to-oss/</guid>
      <description>はじめに &amp;nbsp; 本章はAlibabaCloud LogServiceを使ってOSSへデータを送ります。ゴールとしては以下のような構成図になります。 また、OSSにデータ収集後、E-MapReduceでHDFSへのETL処理がありますが、こちらは「OSSとE-MapReduce編」「ETL編」にて重複するため、割愛させていただきます。 （この章のゴールは外部データソースをOSSへ集約する、のみとなります）
Fluend とは &amp;nbsp; Fluendはデーモン上で動作する、データのやりとりを管理するソフトウェアです。 Fluentd は input, buffer, output という以下の役割を持っています。
 必要なデータを取り出す (input)  そのデータを必要に応じて分解(パース)する データのタイムスタンプを管理する  必要なところにデータを届ける (output)  そのデータを必要に応じて整形(フォーマット)して保存する  データを紛失しないよう管理する (buffer)  やりとりの途中で何かエラーが起きたらリトライする   他、特徴として、以下があります。
 ログはタグで管理される JSON形式 様々なプラグインがあり、OSSやMySQL、Hadoop HDFSなど自由に接続が可能  他、詳しいことはFluend公式サイトを参照してください。
また、Fluentdのガイドブックもありますので、使用方法はこちらを参考にしてください。
https://docs.fluentd.org/
Fluendの導入 ECSにFluendをインストールし、OSSへデータを送ってみます。ECSはCentOS 7.6です。
Step1. td-agentをインストールするshellを入手し、Shellを実行
[root@bigdatatest ~]# curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent3.sh | sh % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 849 100 849 0 0 5773 0 --:--:-- --:--:-- --:--:-- 5815 ============================== td-agent Installation Script ============================== This script requires superuser access to install rpm packages.</description>
    </item>
    
    <item>
      <title>SLBの構築</title>
      <link>https://www.sbcloud.co.jp/help/scenario/terraform/slb-setting-sample/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/scenario/terraform/slb-setting-sample/</guid>
      <description>SLBの構築 &amp;nbsp; SLB（Server Load Balancer）は、外部インターネット、もしくは内部イントラネットからパブリックIPまたはプライベートIPへ届くインバウンドトラフィックを予め設定したSLBの転送ルールに従って、複数のECSインスタンス間のインバウンドトラフィックを分散および制御し、アプリケーションの可用性を高めるサービスです。SLBを使うことで、以下のメリットがあります。
 高可用性・・・完全冗長モードとして障害や災害時でもで稼働します。 スケーラブル・・・サービスニーズに合わせて必要な台数分へサーバを増減します。 費用対効果・・・必要なリソースの分だけ使用なので、通常の負荷分散ハードウェアと比べてコスト削減します。 セキュリティ・・・SLBはトラフィックを分散するだけでなくHTTP Flood攻撃やSYN Flood攻撃など、最大5GbitsのDDoS攻撃から防御できます。  SLBのより詳しい詳細はこちらを参照ください。
&amp;nbsp; TerraformでSLBを使ったECSインスタンスを作成してみます。ゴールの構成図は以下の通りです。
それぞれのパラメータは以下の通りです。
ネットワーク構成:
   リソース リソース名 パラメータ 必須 設定値 内容     alicloud_vpc vpc name 任意 ${var.project_name}-vpc VPC の名称。この例の場合、SLB-Sample-for-Terraform-vpc として表示されます。    vpc cidr_block 必須 192.168.1.0/24 VPC の CIDR ブロック    vpc description 任意 Enable SLB-Setteing-Sample vpc VPC の説明。   alicloud_vswitch vsw name 任意 ${var.project_name}-vswitch vswitch の名称。この例の場合、SLB-Sample-for-Terraform-vswitch として表示されます。    vsw vpc_id 必須 ${alicloud_vpc.</description>
    </item>
    
    <item>
      <title>EnbulkからOSSへ</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/018_enbulk-to-oss/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/018_enbulk-to-oss/</guid>
      <description>はじめに &amp;nbsp; 本章はAlibabaCloud LogServiceを使ってOSSへデータを送ります。ゴールとしては以下のような構成図になります。 また、OSSにデータ収集後、E-MapReduceでHDFSへのETL処理がありますが、こちらは「OSSとE-MapReduce編」「ETL編」にて重複するため、割愛させていただきます。 （この章のゴールは外部データソースをOSSへ集約する、のみとなります）
Enbulk とは &amp;nbsp; Fluendはデータをストリーミングで収集するに対し、データをバッチで収集するツール。
並列データ転送ツール『Embulk』リリース！ http://frsyuki.hatenablog.com/entry/2015/02/16/080150
Enbulkの導入 ECSにEnbulkをインストールし、S3からOSSへデータを送ってみます。ECSはCentOS 7.6です。 注意したいこととして、embulkは近年出たばかりのツールで、2019/08/15現時点、AlibabaCloud OSSのInput/Outputプラグインは未開発状態です。ここではFTPを利用した方法で対処します。 Step1. javaのインストール EmbulkはJavaアプリケーションなので、Javaがインストールされていることを確認してください。
$ which java もしJavaが入ってないのであれば、インストールしてください。
$ sudo yum install java-1.8.0-openjdk Javaが無事インストールされてることを確認します。
[root@metabase ~]# which java /usr/bin/java [root@metabase ~]# java -version openjdk version &amp;#34;1.8.0_222&amp;#34; OpenJDK Runtime Environment (build 1.8.0_222-b10) OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode) [root@metabase ~]#  
Step2. Embulkをダウンロードして配置します。
[root@metabase ~]# curl --create-dirs -o ~/.embulk/bin/embulk -L &amp;#34;https://dl.embulk.org/embulk-latest.jar&amp;#34; % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0 0 0 0 607 0 0 661 0 --:--:-- --:--:-- --:--:-- 661 100 43.</description>
    </item>
    
    <item>
      <title>RDSの構築</title>
      <link>https://www.sbcloud.co.jp/help/scenario/terraform/rds-setting-sample/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/scenario/terraform/rds-setting-sample/</guid>
      <description>&amp;nbsp; TerraformでデータベースサービスであるRDSを作ってみます。ゴールの構成図は以下の通りです。
またECSからRDS for MySQLへ接続するためにdocker-composeを使います。docker-composeはコンテナオーケストレーションの一つで、環境構築を再現するのが楽になる手法です。docker-compose.ymlファイルは以下の通りです。
version: &#39;3&#39; services: # MySQL db: image: mysql:5.7 container_name: mysql_host environment: - MYSQL_HOST=&#39;rds-sample.mysql.japan.rds.aliyuncs.com&#39; - MYSQL_DATABASE=&#39;rds_setting_sample&#39; - MYSQL_USER=&#39;test_user&#39; - MYSQL_PASSWORD=&#39;!Password2019&#39; - TZ=&#39;Asia/Tokyo&#39; command: mysqld --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci volumes: - ./docker/db/data:/var/lib/mysql - ./docker/db/my.cnf:/etc/mysql/conf.d/my.cnf - ./docker/db/sql:/docker-entrypoint-initdb.d ports: - 3306:3306  それぞれのパラメータは以下の通りです。
ネットワーク構成:
   リソース リソース名 パラメータ 必須 設定値 内容     alicloud_vpc vpc name 任意 ${var.project_name}-vpc VPC の名称。この例の場合、RDS-Sample-for-Terraform-vpc として表示されます。    vpc cidr_block 必須 192.</description>
    </item>
    
    <item>
      <title>Apache ArrowからOSSへ</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/019_apache-arrow-to-oss/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/019_apache-arrow-to-oss/</guid>
      <description>はじめに &amp;nbsp; 本章はAlibabaCloud LogServiceを使ってOSSへデータを送ります。ゴールとしては以下のような構成図になります。 また、OSSにデータ収集後、E-MapReduceでHDFSへのETL処理がありますが、こちらは「OSSとE-MapReduce編」「ETL編」にて重複するため、割愛させていただきます。 （この章のゴールは外部データソースをOSSへ集約する、のみとなります）
Apache Arrow とは &amp;nbsp; Apache Arrowは様々な言語で使えるIn-Memoryデータ変換処理プラットフォームです。大規模なBigDataでSpark以外の手法の一つです。見た目、Sparkにちょっと似ていますが、こちらの利点としては以下の通りです。
 インメモリの列指向データフォーマット。PythonのPandas問題を解決するために開発 CPU/GPUのキャッシュメモリを利用して大量のデータの処理効率化 データ交換（シリアライズ、転送、デシリアライズ）の高速化に特化 実装コストは非常に低い PySparkなどSparkと連携することで、CPU、NW転送の観点上、今より数十倍高速化が可能 OLAP、OLTP、DeepLearningなど様々な分野で活躍 データの交換をするならArrow、データの永続化をするならSpark  参考：PythonのPandas問題 https://qiita.com/tamagawa-ryuji/items/3d8fc52406706ae0c144
より詳しくはApache Arrowの公式ガイドラインを参照してください。 https://arrow.apache.org/ https://arrow.apache.org/docs/format/README.html

それではApache Arrowを使ってECSにあるcsvファイルをhdfs_Parquetへ変換します。 &amp;gt;注意として、ECSはOSSへのアクセス権限を持ってることが前提となります。
Apache ArrowのParquet形式変換で様々なオプションがありますので、こちらを参考にしてください。 https://arrow.apache.org/docs/python/parquet.html
Apache Arrowの使い方 Arrowは多くの言語をサポートしています。（現在も様々な言語へ開発中） 今回はPythonを使います。 https://github.com/apache/arrow
Step1. pip install arrowでインストールします。またpandasも必要なのでなければpip install pandasとインストールしましょう。
[root@metabase ~]# pip install arrow DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.</description>
    </item>
    
    <item>
      <title>Kubernetesの構築と設定</title>
      <link>https://www.sbcloud.co.jp/help/scenario/terraform/kubernetes-setting-sample/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/scenario/terraform/kubernetes-setting-sample/</guid>
      <description>&amp;nbsp; 簡単なkuberntesクラスターを作ってみます。シングルゾーンによるクラスタでの作成になります。ゴールの構成図は以下の通りです。
それぞれのパラメータは以下の通りです。
ネットワーク構成:
   リソース リソース名 パラメータ 必須 設定値 内容     alicloud_vpc vpc name 任意 ${var.project_name}-vpc VPC の名称。この例の場合、Kubernetes-Sample-for-Terraform-vpc として表示されます。    vpc cidr_block 必須 192.168.1.0/24 VPC の CIDR ブロック    vpc description 任意 Enable k8s-Setteing-Sample vpc VPC の説明。   alicloud_vswitch vsw name 任意 ${var.project_name}-vswitch vswitch の名称。この例の場合、Kubernetes-Sample-for-Terraform-vswitch として表示されます。    vsw vpc_id 必須 ${alicloud_vpc.vpc.id} アタッチするVPCのID    vsw cidr_block 必須 192.</description>
    </item>
    
    <item>
      <title>RDS for MySQLからOSSへ</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/020_rds-for-mysql-to-oss-sqoop-and-spark/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/020_rds-for-mysql-to-oss-sqoop-and-spark/</guid>
      <description>はじめに &amp;nbsp; 本章はSqoopを使ってRDS for MySQLからOSSへデータを送ります。ゴールとしては以下のような構成図になります。 また、OSSにデータ収集後、E-MapReduceでHDFSへのETL処理がありますが、こちらは「OSSとE-MapReduce編」「ETL編」にて重複するため、割愛させていただきます。 （この章のゴールは外部データソースをOSSへ集約する、のみとなります）
SQOOPとは &amp;nbsp; Apache SqoopはHadoopとリレーショナルデータベースなどの構造化データストアとの間で、大量のデータを効率的に転送するために設計されたツールです。
   From To 備考     MySQL HDFS    MySQL Hive &amp;ndash;hive-importオプションを付与   PostgreSQL HDFS    PostgreSQL Hive &amp;ndash;hive-importオプションを付与    他、jdbcドライバがある限り、OracleやSQL ServerからHDFSやHiveテーブルへSqoop移植することも可能です。
移植してみる Sqoopを使ってRDS for MySQLにあるテーブルをHive Tableへ移植します。
環境について    Clustor instance Type 台数     Hadoop EMR-3.22.0 MASTER ecs.sn2.large 1    CORE ecs.</description>
    </item>
    
    <item>
      <title>Webアプリケーションの構築</title>
      <link>https://www.sbcloud.co.jp/help/scenario/terraform/web-application/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/scenario/terraform/web-application/</guid>
      <description>&amp;nbsp; こちらはAlibabaCloud公式サイトにあるソリューション構築例を通じての紹介になります。IDCなどデータセンターにて、スケーラブルで世界規模で利用可能なWebアプリケーションを開発および展開するのは、多くの手作業から工数がかかり、またトラフィックに応じてリソースの効率さが悪くなってしまう課題があります。しかしAlibabaCloudで構築すると、それらの課題が払拭されます。それだけでなく、上に、投資収益率（ROI）も向上するメリットがあります。
 すぐに着手できる配置構成 必要な分だけリソースを提供（オンデマンドサーバープロビジョニング） 単一障害点（SPOF）なし 多重層のセキュリティ保護あり  
&amp;nbsp; TerraformでWebアプリケーションを作ってみます。ゴールの構成図は以下の通りです。
それぞれのパラメータは以下の通りです。
ネットワーク構成:
   リソース リソース名 パラメータ 必須 設定値 内容     alicloud_vpc vpc name 任意 ${var.project_name}-vpc VPC の名称。この例の場合、Accelerated-Content-Delivery-for-Terraform-vpc として表示されます。    vpc cidr_block 必須 192.168.0.0/16 VPC の CIDR ブロック    vpc description 任意 VPC for ${var.project_name} VPC の説明。この場合VPC for Accelerated-Content-Delivery-for-Terraform として表示されます。   alicloud_vswitch web name 任意 ${var.project_name}-web-vswitch vswitch の名称。この例の場合、Accelerated-Content-Delivery-for-Terraform-web-vswitch として表示されます。    web vpc_id 必須 ${alicloud_vpc.</description>
    </item>
    
    <item>
      <title>AlibabaCloud OSSから別のOSSへ（移植）</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/021_alibabacloud-oss-to-another-oss-migration-/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/021_alibabacloud-oss-to-another-oss-migration-/</guid>
      <description> はじめに &amp;nbsp; 本ページはAlibabaCloud OSSから別のOSSへデータを移植する方法をまとめます。 本ページは具体的な手法より、どんな手法があるかをメインに記載します。 一部、URLにある手順はAWS S3をメインとしていますが、こちらはAlibabaCloud OSSでも同じことなので、参考にしてください。
OSSImportツール（スタンドアロン）を使った移植 OssImportのアーキテクチャと構成、ダウンロードページ
https://jp.alibabacloud.com/help/doc-detail/56990.html
AWS S3からAlibaba Cloud OSSへのマイグレーション手順
https://www.sbcloud.co.jp/file/98012380859496046
AlibabaCloudへのマイグレーション -ストレージ編-
https://www.sbcloud.co.jp/entry/2018/10/31/migration_oss/
OSSImportツール（分散モード）を使った移植（分散版） OssImportのアーキテクチャと構成、ダウンロードページ
https://jp.alibabacloud.com/help/doc-detail/56990.html
OssImport を使用したデータの移行
https://jp.alibabacloud.com/help/doc-detail/59922.htm
分散デプロイについて
https://jp.alibabacloud.com/help/doc-detail/57057.htm
emr-toolを使って移植する方法 AlibabaCloud E-MapReduceにてAlibabaCloudのemr-toolをセットアップ、hdfsデータの保存先(接続先パス、エンドポイント）を目的となるAlibabaCloud OSSへ指定し移植します。
HDFS の OSS へのバックアップ
https://jp.alibabacloud.com/help/doc-detail/63822.html
Spark分散を使った移植方法 AWS EMRにてSpark分散処理を実施、保存先(接続先パス、エンドポイント）をAlibabaCloud OSSへ指定するだけです。

最後に OSSからのデータ移植方法は様々な方法があります。ここには書いていない方法もありますので、検証次第、追記したいと思います。
またOSSから別のOSSへ移植するとき、注意したいことが以下の三点です。
 OSSとのNW距離（リージョンが近ければGood） NW帯域（データが多いのであれば分散で移植した方がベター） （アカウント分離している場合）OSSからの転送料金（データが多いほどOut料金が高くなります）  これを踏まえてOSSから別OSSへ気軽なデータ移植（Import）ができれば幸いです。 </description>
    </item>
    
    <item>
      <title>高速コンテンツ配信の実現</title>
      <link>https://www.sbcloud.co.jp/help/scenario/terraform/accelerated-content-delivery/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/scenario/terraform/accelerated-content-delivery/</guid>
      <description>&amp;nbsp; こちらはAlibabaCloud公式サイトにあるソリューション構築例を通じての紹介になります。従来のWebアプリケーションアーキテクチャでは、Webアプリケーションが大量のリクエストトラフィックを受け取ると、サーバーが過負荷になり、サイトが遅くなったりサーバーがクラッシュしたりする可能性があります。また地理的に異なる場所に分散していると、コンテンツが1か所から配信されるため、待ち時間の問題が発生する可能性があります。そのためにWebアプリケーションは高速でコンテンツ配信することが望ましいです。
 グローバル配信が可能 静的および動的コンテンツのアクセラレーション 待ち時間の短縮などパフォーマンス改善  
&amp;nbsp; TerraformでWebアプリケーションを作ってみます。ゴールの構成図は以下の通りです。
それぞれのパラメータは以下の通りです。
ネットワーク構成:
   リソース リソース名 パラメータ 必須 設定値 内容     alicloud_vpc vpc name 任意 ${var.project_name}-vpc VPC の名称。この例の場合、Accelerated-Content-Delivery-for-Terraform-vpc として表示されます。    vpc cidr_block 必須 192.168.0.0/16 VPC の CIDR ブロック    vpc description 任意 VPC for ${var.project_name} VPC の説明。この場合VPC for Accelerated-Content-Delivery-for-Terraform として表示されます。   alicloud_vswitch web name 任意 ${var.project_name}-web-vswitch vswitch の名称。この例の場合、Accelerated-Content-Delivery-for-Terraform-web-vswitch として表示されます。    web vpc_id 必須 ${alicloud_vpc.</description>
    </item>
    
    <item>
      <title>AlibabaCloud OSSから別のOSSへ（同期）</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/022_alibabacloud-oss-to-another-oss-synchronization-/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/022_alibabacloud-oss-to-another-oss-synchronization-/</guid>
      <description> はじめに &amp;nbsp; 本ページはAlibabaCloud OSSから別のOSSへデータを同期する方法をまとめます。 本ページは具体的な手法より、どんな手法があるかをメインに記載します。
クロスリージョンレプリケーションを使った同期方法   注意
* 2019/8/30 現在、クロスリージョンレプリケーション機能は、中国本土の異なるリージョン間、および米国西部1（シリコンバレー）と米国東部1（バージニア）リージョン間でのみサポートされています。
* クロスリージョンレプリケーション機能はベータテスト段階にあり、現在無料です。この関数は、公式にリリースされた後に課金されます。
  参考：クロスリージョンレプリケーション https://www.alibabacloud.com/help/doc-detail/31864.htm

最後に OSSの同期、クロスリージョンレプリケーションの手法があります。こちらは現在まだ開発段階なので、続報に期待したいと思います。 </description>
    </item>
    
    <item>
      <title>オートスケーリングの実現</title>
      <link>https://www.sbcloud.co.jp/help/scenario/terraform/auto-scaling/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/scenario/terraform/auto-scaling/</guid>
      <description>&amp;nbsp; こちらはAlibabaCloud公式サイトにあるソリューション構築例を通じての紹介になります。
プロビジョニング済みのECSインスタンスをメインとするWebアプリケーションにて、予測が難しいトラフィックニーズに応じて、必要なECSインスタンス台数を増減してくれます。これにより、アプリケーションを止めることなく稼働し続けることが出来ます。同時にリソースに応じた需要増/減から必要なコスト管理も実現出来ます。
 アプリケーションの稼働時間・堅牢性向上 サーバーの自動プロビジョニング ニーズに応じたコスト管理  
&amp;nbsp; TerraformでWebアプリケーションを作ってみます。ゴールの構成図は以下の通りです。
それぞれのパラメータは以下の通りです。
ネットワーク構成:
   リソース リソース名 パラメータ 必須 設定値 内容     alicloud_vpc vpc name 任意 ${var.project_name}-vpc VPC の名称。この例の場合、Accelerated-Content-Delivery-for-Terraform-vpc として表示されます。    vpc cidr_block 必須 192.168.0.0/16 VPC の CIDR ブロック    vpc description 任意 VPC for ${var.project_name} VPC の説明。この場合VPC for Accelerated-Content-Delivery-for-Terraform として表示されます。   alicloud_vswitch web name 任意 ${var.project_name}-web-vswitch vswitch の名称。この例の場合、Accelerated-Content-Delivery-for-Terraform-web-vswitch として表示されます。    web vpc_id 必須 ${alicloud_vpc.</description>
    </item>
    
    <item>
      <title>開発環境構築について</title>
      <link>https://www.sbcloud.co.jp/help/best-practice/bigdata/023_development_environment_buildup_set_and_buildup_method/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/bigdata/023_development_environment_buildup_set_and_buildup_method/</guid>
      <description>はじめに &amp;nbsp; Alibaba Cloud SDKはGo、Node.js、RUSH、など幅広い分野に展開されていますが、AlibabaCloudのBigDataプロダクトはScala/Java/Pythonを主に利用します。 そのため、本章ではローカルのMac OS上でPython及びPlayFrameworkの開発を開始するための環境構築手順について記載します。

環境 Mac OS Mojave (10.14.x）

Homebrew Homebrewの導入 Mac用パッケージ管理ソフト Homebrew をインストールします。 Homebrew（ホームブルー）は、macOSオペレーティングシステム上でソフトウェアの導入を単純化するパッケージ管理システムのひとつです。 Homebrewを導入することで、Pythonの構築など、後の導入が楽になります。
Homebrewのインストール ターミナルを開いてHomebrew公式サイト に書かれている以下コマンドを実行します。 画面の指示に従ってキーやパスワード入力して、しばらく待つとインストールが終わります。
$ /usr/bin/ruby -e &amp;#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master Homebrewのインストール確認 以下コマンドでHomebrewが無事インストールできたかを確認します。
$ brew doctor  ターミナルに以下が表示されれば完了です。 &amp;gt; Your system is ready to brew.
Homebrewの更新 brewコマンドでパッケージをインストールしたものの、目的のバージョンがないときは、brewのバージョンが古い可能性がありますので、以下コマンドで更新チェックをします。
$ brew update  
Python開発環境構築  PyCharm  JetBrains社製のPython用IDE（統合開発環境） 無償版（Community Edition）と有償版（Ultimate Edition）があり、有償版はDjangoなどのWebフレームワークをサポートしています。 ※無償版でも十分実用的なため今回は無償版を利用します   
pyenv導入 pyenvは1台のPC内でPythonの異なるバージョンを切り分け、管理するためのツールです。例えば、Python2.7と3.6混合で利用したい場合は、pyenvが非常に役立ちます。 ターミナル上で以下コマンドを使ってpyenvをインストールします。
$ brew install pyenv  ターミナルで以下コマンドを実行し、pyenvのフォルダにPATHを通します。</description>
    </item>
    
    <item>
      <title>KubernetesによるコンテナでWordPress作成</title>
      <link>https://www.sbcloud.co.jp/help/scenario/terraform/web-application-on-kubernetes/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0900</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/scenario/terraform/web-application-on-kubernetes/</guid>
      <description>&amp;nbsp; KubernetesによるコンテナでWordPressを作成します。流れは以下の通りになります。
 AlibabaCloudでKubernetesクラスターを生成 kube_configを環境変数にて設定 KubernetesクラスターのローカルボリュームにてWordPressとMySQLをインストール  
こちらはAlibabaCloud Terraformのサンプル集を通じての紹介になります。
Kubernetesでクラスタ生成 &amp;nbsp; KubernetesによるコンテナでWordPressを作成します。流れは以下の通りになります。

&amp;nbsp; TerraformでWebアプリケーションを作ってみます。step1のゴール構成図は以下の通りです。
それぞれのパラメータは以下の通りです。
ネットワーク構成:
   リソース リソース名 パラメータ 必須 設定値 内容     alicloud_vpc vpc name 任意 ${var.project_name}-vpc VPC の名称。この例の場合、Web-App-on-k8s-for-Terraform-vpc として表示されます。    vpc cidr_block 必須 192.168.1.0/24 VPC の CIDR ブロック    vpc description 任意 Enable k8s-Setteing-Sample vpc VPC の説明。   alicloud_vswitch vsw name 任意 ${var.project_name}-vswitch vswitch の名称。この例の場合、Web-App-on-k8s-for-Terraform-vswitch として表示されます。    vsw vpc_id 必須 ${alicloud_vpc.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.sbcloud.co.jp/help/best-practice/network/cisco891f/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.sbcloud.co.jp/help/best-practice/network/cisco891f/</guid>
      <description>本設定例では、VPCに作成したVPN Gatewayを、お客様拠点に設置したCisco ルーターとIPsec-VPNで接続します。
事前準備 ネットワークや IP アドレス等を事前に設計し、VPN Gatewayを購入します。
本設定例では、クラウド側のVPC (セグメント 192.168.0.0/24) とCiscoルーター側 (セグメント 192.168.100.0/24) をRoute-basedで接続します。
本設定例について Alibaba CloudのVPCとの接続を保証するものではありません。
2019年 5 月の仕様に基づいて記載しています。確認しているファームウェアは下記のとおりです。今後、サービス内容の変更や、仕様変更などによって接続できなくなる可能性があります。
本設定例でテスト済みのCiscoルーターは以下になります。
   モデル バージョン     C891FJ-K9 Version 15.4(3)M8    Ciscoルーターに関する情報および設定方法については、Ciscoルーターお客様相談センターまでお問い合わせください。
設定手順 ステップ 1：VPN Gateway の設定  対象VPCにVPN Gatewayとカスタマーゲートウェイを作成します。カスタマーゲートウェイの設定ではお客様拠点 ルーターのグローバルIPアドレスを使って設定します。
 IPsec ConnectionsよりVPN接続を作成します。
   以下の項目を入力します  「名前」任意の識別名を入力します。 「VPN Gateway」作成したVPN Gateway名を選択します。 「カスタマーゲートウェイ」　作成したカスタマーゲートウェイを選択します。 「ローカルネットワーク」クラウド側ネットワーク (0.0.0.0/0) を入力します。 「リモートネットワーク」お客様拠点側ネットワーク ( 0.0.0.0/0 ) を入力します。 「今すぐ有効化」“はい”を選択します。 「高度な構成」有効にします。 「事前共有鍵」お客様拠点側ルーターと同一の任意の共有鍵を入力します。 「バージョン」ikev2を選択します。</description>
    </item>
    
  </channel>
</rss>